\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{graphicx}
\usepackage{pdfpages}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{geometry}
\usepackage{fullpage}
\usepackage{times}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{ulem}

\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{eqparbox}

\geometry{a4paper, total={170mm,257mm}, left=20mm, top=20mm}
\graphicspath{./figures}
\title{Research Notes}
\author{Luke Kurlandski}

\makeatletter
\def\endthebibliography{%
	\def\@noitemerr{\@latex@warning{Empty `thebibliography' environment}}%
	\endlist
}
\makeatother

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Efficient Estimation of Word Representations in Vector Space}

\subsection*{Metadata}

\noindent Authors: Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean

\noindent Published: 2013

\noindent Read: 04/2022

\subsection*{Reaction}
\begin{itemize}
\item word2vec
\end{itemize}

\subsection*{Further Reading}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{itemize}
	\item
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Distributed Representation of Words and Phrases and their Compositionality}

\subsection*{Metadata}

\noindent Authors: Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Corrado, Jeff Dean

\noindent Published: 2013

\noindent Read: 04/2022

\subsection*{Reaction}
\begin{itemize}
\item word2vec
\end{itemize}

\subsection*{Further Reading}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{itemize}
	\item
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}

\subsection*{Metadata}

\noindent Authors: Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova

\noindent Published: 2018

\noindent Read: 04/2022

\subsection*{Reaction}
\begin{itemize}
\item BERT
\item contextual word embeddings can differentiate between different meanings of words
\end{itemize}

\subsection*{Further Reading}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{itemize}
	\item
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Multi-task Learning based Pre-trained Language Model for Code Completion}

\subsection*{Metadata}

\noindent Authors: Fang Liu, Ge Li, Yunfei Zhao, Zhi Jin

\noindent Published: 2020

\noindent Read: 07/2022

\subsection*{Reaction}
\begin{itemize}
\item Similar to BERT but for code
\end{itemize}

\subsection*{Further Reading}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{itemize}
	\item
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{code2vec: Learning Distributed Representations of Code}

\subsection*{Metadata}

\noindent Authors: Uri Alon, Meital Zilberstein, Omer Levy, Eran Yahav

\noindent Published: 2019

\noindent Read: 07/2022

\subsection*{Reaction}
\begin{itemize}
\item Similar to word2vec but for code
\end{itemize}

\subsection*{Further Reading}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{itemize}
	\item
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{code2seq: Generating Sequences From Structured Representations of Code}

\subsection*{Metadata}

\noindent Authors: Uri Alon, Shaked Brody, Omer Levy, Eran Yahav

\noindent Published: 2019

\noindent Read: 07/2022

\subsection*{Reaction}
\begin{itemize}
\item Builds upon code2vec
\end{itemize}

\subsection*{Further Reading}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{itemize}
	\item
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Attention is All You Need}

\subsection*{Metadata}

\noindent Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, ≈Åukasz Kaiser, Illia Polosukhin

\noindent Published: 2017

\noindent Read: 07/2022

\subsection*{Reaction}
\begin{itemize}
\item Original Transformer paper
\end{itemize}

\subsection*{Further Reading}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{itemize}
	\item
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Structural Language Models of Code}

\subsection*{Metadata}

\noindent Authors: Uri Alon, Roy Sadaka, Omer Levy, Eran Yahav

\noindent Published: 2018

\noindent Read: 08/2022

\subsection*{Reaction}
\begin{itemize}
\item 
\end{itemize}

\subsection*{Further Reading}
\begin{itemize}
	\item 
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
	\item Focuses on any code completion, i.e., predicting a missing code segment from surround code
	\item Differs from other code completions in that it is unrestricted and more general purpose
	\item Introduces Structural Language Modeling (SLM) - estimates the probability of a program's AST
	\item Uses joint modeling of source and target code, rather than multimodal encoders and decoders
\end{itemize}
Code Generation as Structural Language Modeling
\begin{itemize}
	\item Model probability of a program, analogous to probability of a sentence in LMs
	\item AST should allow the model to generalize better between languages
	\item Computes the probability of an AST via a DFS traverse and the chain rule
	\item Essentially ensures the target node for completion is last in the DFS traversal, so the entire known sequence can be modeled
	\item Models a partial tree as a set of paths: the paths from every leaf to $a_t$ and the path from the root to $a_t$
	\item Uses EOStok and EOSnode to end the sequence of token/node generation which controls the depth and breadth of the ASTs generated
	\item Decomposes terminal nodes into a sequence of terminal nodes by splitting the node into subtokens, e.g., toLowerCase becomes to...lower...case...EOStok
\end{itemize}
Model Architecture
\begin{itemize}
	\item Each AST node is represented using three embedding matrices: subtoken, type, and index
	\item The entire AST path is encoded using an LSTM whose final states are extracted
	\item Multiple AST paths are aggregated into a single vector representation
	\item Uses a copy mechanism to assist with predicting because programs often have repetition
\end{itemize}
Related Work
\begin{itemize}
	\item Frames code generation as predicting the next node in all partial AST paths, so generalizes many other previous works
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Automated malware detection using artifacts in forensic memory images}

\subsection*{Metadata}

\noindent Authors: Rayan Mosli, Rui Li, Bo Yuan, Yin Pan

\noindent Published: 2016

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item Investigates a heuristic approach to malware detection already active on the system.
\item Trains classifiers on three features extracted from memory images: registry activity, imported libraries, and API function calls.
\item Uses malware samples gathered from VirusShare.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item Heuristic machine learning malware detection methods:
	\begin{itemize}
	\item ``Analysis of malware behavior: Type classification using machine learning'' (2015)
	\item ``Analysis of features selection and machine learning classifier in android malware detection'' (2014)
	\item ``Malicious behavior detection using windows audit logs'' (2015)
	\item ``Amal: High-fidelity, behavior-based automated malware analysis and classification'' (2015)
	\item ``Three- phase behavior-based detection and classification of known and unknown malware''
	\end{itemize}
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

\noindent Introduction
\begin{itemize}
	\item Investigates three feature types from memory images: registry activity, imported libraries, and API function calls
	\item Traditional approaches include signature scanning and monitoring running malware
	\item Memory images and memory forensics involve examining a memory dump
	\item Uses tools like Memoryze, WinPMEM, Volatility, and Rekall
\end{itemize}

\noindent Related Work
\begin{itemize}
	\item Current malware detection based on static and dynamic malware features
	\item Memory-based detection has several advantages, such as 1) compressed malware must decompress in memory, 2) artifacts can be extracted without a VM, 3) can be used to detect memory-only malware
\end{itemize}

\noindent Methodology
\begin{itemize}
	\item Used Tfidf vectorization of the registry activity, API calls, and DLL imports
	\item Used grid searching to trim unimportant features
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{A Behavior Based Approach for Malware Detection}

\subsection*{Metadata}

\noindent Authors: Rayan Mosli, Rui Li, Bo Yuan and Yin Pan

\noindent Published: 2017

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item Handles are pointers used to access system objects that must be opened and closed.
\item This work uses handles as a heuristic measure to identify malware with machine learning.
\item Uses malware samples gathered from VirusShare.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

\begin{itemize}
	\item Signature based detection and machine learning from static malware features are both easily defeated by anti detection techniques
	\item Behavioral based detection is more sensitive, but requires running the malware in sandbox environment
	\item Handles are pointers used to access system objects without knowing their location in memory
	\item Handles must be opened and closed
	\item This approach uses the number of handles accessed to assess if a program is malicious or not
	\item Section handles and process handles were major indicators of malware
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{A General Path-Based Representation for Predicting Program Properties}

\subsection*{Metadata}

\noindent Authors: Uri Alon, Meital Zilberstein, Omer Levy, Eran Yahav

\noindent Published: 2018

\noindent Read: 07/2022

\subsection*{Summary}
\begin{itemize}
\item One of the great challenges in code analysis tasks is determining an effective representation of code for learning.
\item Instead of treating source code as a stream of tokens, this work represents source code using paths in its abstract syntax tree.
\item This approach is more general than sequence approaches and less language specific.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

\begin{itemize}
	\item
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{A systematic Evaluation of Large Language Models of Code}

\subsection*{Metadata}

\noindent Authors: Frank F. Xu, Uri Alon, Graham Neubig, Vincent Josua Hellendoorn

\noindent Published: 2022

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item Performs a systematic evaluation of several open/closed source large language models of code.
\item Produces a new model, PolyCoder, intended to be multi-lingual, but does not achieve high performance.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item Does not mention code2vec or code2seq, which is unusual because Uri Alon is a co-author.
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item ``Evaluating large language models trained on code'' (2021) Codex code model
\item ``Language models are few-shot learners'' (2020) GPT-3 code model
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item Most of the top performing code language models are not publicly accessible
\item Multilingual vs monolingual LMs
\item Evaluates the LMs: Codex, GPT-J, GPT-Neo, GPT-NeoX, and CodeParrot
\item Trains the first code LM on multiple programming languages (PolyCoder)
\end{itemize}
Related Work
\begin{itemize}
\item Pre-training methods: left-to-right, masked, and encoder-decoder LMs
\item Left-to-right autoregressive LMs predict the probability of a token given previous tokens and are particularly useful for code generation tasks
\item Masked LMs predict the probability of a token given its context and can provide more powerful modeling of an entire sequence's representation
\item Encoder-decoder LMs use an encoder to map an input sequence using some form of pre-training objective, then a left-to-right LM decoder and are effective at sequence to sequence.
\item The main code datasets are can be pure source code or a mixture of code and natural text (the Dump)
\end{itemize}
Evaluation Settings and Models
\begin{itemize}
\item Extrinsic evaluation performed with code generation
\item Intrinsic evaluation performed with perplexity
\item Deduplicated training source code files using hashes
\end{itemize}
Results and Conclusions
\begin{itemize}
\item PolyCoder tends to be outperformed in the extrinsic evaluations
\item For the C language, PolyCoder has the lowest perplexity (good)
\item Perplexity trends closely with the HumanEval benchmark and is probably a good, efficient metric for evaluation
\item Generally, larger models perform better, but Codex performs disproportionally well
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{A Comprehensive Review on Malware Detection Approaches}

\subsection*{Metadata}

\noindent Authors: √ñmer Aslan, Refik Samet

\noindent Published: 2020

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item This paper provides an overview on malware detection approaches, including: signature, behavior, heuristic, model checking, deep learning, cloud, mobile devices, and IoT-based malware detection.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item Research combining deep learning and malware detection is relatively novel.
\item Contains information about some of the widely-used malware datasets.
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item ``Deep neural network based malware detection using two dimensional binary program features" (2015)
\item ``MtNet: A multi-task neural network for dynamic malware classification" (2016)
\item ``Droid‚ÄìSec: Deep learning in Android malware detection" (2014)
\item ``Adversarial malware binaries: Evading deep learning for malware detection in executables" (2018)
\item ``Effective Android malware detection with a hybrid model based on deep auto encoder and convolutional neural network" (2018)
\item ``MALDC: A depth detection method for malware based on behavior chains" (2019)
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
	\item Signature-based detection cannot detect unknown/novel malware species
	\item Behavioral, heuristic, and model-based detection are being used
\end{itemize}
Problem Definition
\begin{itemize}
	\item Malware detection is NP-complete, so no method can be perfect
	\item Obfuscation techniques include: encryption (in various levels of complexity, e.g., oligomorphic/polymorphic), metamorphic (dynamic code hiding), stealth (difficult to analyze correctly), and packaging (compressed and encrypted malware)
\end{itemize}
Malware Detection Techniques and Algorithms
\begin{itemize}
\item Three stages of malware detection: malware analysis, feature extraction, and classification
\item Malware analysis answers how the malware works, what is affected
\item static vs dynamic analysis, both begin with reverse engineering
\item Feature extraction is most commonly done with ngrams or graph-based models
\item NGrams builds and ngram model out of system calls or API calls
\item graph-based model builds graph with system calls as vertices and relationship between them as edges
\item Datasets:
	\begin{itemize}
	\item NSL-KDD
	\item Drebin
	\item Microsoft malware classification challenge - requires feature extraction
	\item ClaMP 
	\item AAGM
	\item EMBER
	\end{itemize}
\item a variety of ML algorithms have been shown to be successful (no mention of DL in this paper)
\end{itemize}
Malware Detection Approaches
\begin{itemize}
\item Signature based detection is being supplemented with behavior, heuristic, and model-checking techniques
\item Signature Detection
	\begin{itemize}
	\item Generate a signature from malware executable via a variety of methods: string scanning, top and tail scanning, entry point scanning, and integrity checking
	\item All of the above methods are somewhat vulnerable to basic obfuscation techniques
	\item More advanced methods exist
	\end{itemize}
\item Behavior Detection
	\begin{itemize}
	\item Runs the malware and examines its behaviors, although some malware will not run in protected sandbox environment, thus will be marked as benign
	\item Three steps: determine behaviors, extract features of behaviors, apply classification
	\end{itemize}
\item Heuristic Detection
	\begin{itemize}
	\item Uses a variety of techniques and established rules to detect malware, but is prone to false positives
	\end{itemize}
\item Model-Checking Detection
	\begin{itemize}
	\item Uses a variety of techniques and established rules to detect malware, but is prone to false positives
	\end{itemize}
\item Deep Learning Detection
	\begin{itemize}
	\item Powerful, but can be fooled by evasion techniques
	\item Little-researched topic
	\end{itemize}
\item Cloud Detection
	\begin{itemize}
	\item 
	\end{itemize}
\item Mobile Device Detection
	\begin{itemize}
	\item 
	\end{itemize}
\item IOT Detection
	\begin{itemize}
	\item 
	\end{itemize}
\end{itemize}
Evaluation on Malware Detection Approaches
\begin{itemize}
\item Signature, behavior, heuristic, and model-based techniques are well studied
\item DL, cloud, mobile, and IoT techniques are new
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Malware Classification with Recurrent Networks}

\subsection*{Metadata}

\noindent Authors: Razvan Pascanu, Jack W. Stokes, Hermineh Sanossian, Mady Marinescu, Anil Thomas

\noindent Published: 2015

\noindent Read: 08/2022

\subsection*{Further Reading}
\begin{itemize}
\item ``A survey of malware detec¬≠tion techniques" (2007)
\item ``Large-scale malware classification using random projections and neural networks" (2013)
\item ``A biologically inspired immune system for computers'' (1994) the first malware detection system
\end{itemize}

\subsection*{Summary}
\begin{itemize}
\item Uses RNNs to model the API calls made by malware programs and passes the malware embeddings to classifiers.
\item Presumably, takes a dynamic approach and runs the malware in a VM to attain the API calls.
\item Uses a proprietary Microsoft malware dataset.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item The base model could be extended to a transformer-based model.
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item 
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item Handcrafted feature selection approaches are often not robust to obfuscation
\item RNN learns the language of malware, i.e., LM, by predicting the next API call
\item The hidden state of the RNN is extracted and used as a feature vector, then fed to a different classifier
\item Uses Max Pooling over values of hidden units in time (future works will experiment with Attention)
\item Uses a Bi-directional model, i.e., two separate models one working left to right the other right to left
\end{itemize}
Algorithm Description
\begin{itemize}
\item Max Pooling and Half Frame address limited memory window of RNN and ESN
\item Max pooling selects the maximum hidden state output for each sequence. The sequence representation is the concatenation of the last state and the max pooling layer.
\item Half Frame uses the hidden state from the middle of the sequence and the hidden state from the end of the sequence
\end{itemize}
Experimental Results
\begin{itemize}
\item Uses 114 high level events as initial features
\item Compared to bag of words-based models (unigram and trigram)
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Malware classification with LSTM and GRU language models and a character-level CNN}

\subsection*{Metadata}

\noindent Authors: Ben Athiwaratkun, Jack W. Stokes

\noindent Published: 2019

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item Malware is dynamically analyzed via emulation and a sequence of system calls is extracted.
\item The system calls are modeled using LSTMs and GRUs before feeding embeddings to classifiers.
\item Proposes a novel end-to-end character-level CNN, which does not perform as well as the two-stage process.
\item Uses a proprietary Microsoft malware dataset.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item Creates embeddings for the system calls extracted using dynamic analysis.
\item Doesn't model malware language so much.
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item ``Malware classification with recurrent networks'' (2015) the foundation and baseline for this work
\item Deep learning for malware classification:
	\begin{itemize}
	\item ``Large-scale malware classification using random projections and neural networks'' (2013) uses system calls
	\item ``Deep neural network based malware detection using two dimensional binary program features'' (2015)
	\item ``Mtnet: A multi-task neural network for dynamic malware classification'' (2016)
	\item ``Visualized malware classification based-on convolutional neural network'' (2016)
	\end{itemize}
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item Previous work trained an LM using RNN/ESN then used feature outputs to train a classifier
\item This work uses LSTM, GRU, Attention, and CharCNN as LMs seeking to improve the performance
\item Maps API calls to 113 high-level abstraction operations for features
\end{itemize}
Model
\begin{itemize}
\item Previous work found ESN + Max Pooling and RNN + Max Pooling were the most successful for the LM and an LR classifier for the classifier
\item This work explores a LSTM and GRU for the LM with an Attention Mechanism instead of Max Pooling and MLP/LR classifiers
\item They also deploy a single-stage CharCNN malware classifier forgoing the LM entirely
\end{itemize}
Conclusions
\begin{itemize}
\item LSTM + Max Pooling + LR outperforms other models
\item Demonstrates the benefits of the semi supervised pre-training
\item Demonstrates the efficacy of LMs for file stream events
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Learning and Evaluating Contextual Embedding of Source Code}

\subsection*{Metadata}

\noindent Authors: Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, Kensen Shi

\noindent Published: 2020

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item Developed CuBERT (Code Understanding BERT), a pre-trained contextual Python code understanding model.
\item Fine-tuned CuBERT outperformed word2vec, BiLSTM, and Transformer classification models.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item Concept could be applied to other transformer models, e.g., CuELECTRA.
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item ``A literature study of embeddings on source code'' (2019)
\item ``CodeBERT: A pre-trained model for programming and natural languages'' (2020)
\item ``Global relational models of source code'' (2020)
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item Compared against BiLSTMs and Transformers
\item Classification and code repair
\item Uses raw source code tokens instead of a structured format of code
\end{itemize}
Related Work
\begin{itemize}
\item CodeBERT targets paired natural language and programming language tasks, where NL is paired with PL
\end{itemize}
Experimental Setup
\begin{itemize}
\item Uses Python datasets for pre-training and fine tuning with measures taken to avoid duplication
\item Fine-Tuning Tasks. Five classification and one more complex.
\begin{itemize}
	\item variable misuse classification: given function, classifier must predict whether their is variable misuse anywhere within the function
	\item wrong binary operator: determine if any binary operator in the function is incorrect
	\item ped operand: 
	\item function-docstring mismatch:
	\item exception type: 
	\item variable misuse localization and repair
\end{itemize}
\item Baselines: four variants of word2vec for embeddings, BERT, BiLSTM, and pre-trained BiLSTM
\end{itemize}
Results and Conclusions
\begin{itemize}
\item Contextual code token embeddings prove more beneficial than word embeddings
\item Pre-trained + fine tuned transformer beats the plain old fine tuned transformer
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Large-scale malware classification using random projections and neural networks}

\subsection*{Metadata}

\noindent Authors: George E. Dahl, Jack W. Stokes, Li Deng, Dong Yu

\noindent Published: 2013

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item Random projections reduce the typically sparse feature space of malware representation to dimensions suitable for DNNs.
\item Uses dynamically extracted features from a Microsoft dataset.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item Malware classification also involves massively sparse feature representations
\item Even after feature selection there can be too many features for NN classifiers
\item This work uses random projections to further reduce the dimensionality
\item Values minimizing FP ($<$ .001) more than FN ($<$ .05)
\end{itemize}
System
\begin{itemize}
\item Three features: null-terminated patterns in process memory, tri-grams of system API calls, and distinct combinations of a single system API call and one input parameter
\item Feature selection to reduce the number of features to a reasonable amount, 179k
\item Uses random projections to reduce feature size to a couple of thousand, but also explore PCA
\end{itemize}
Results and Conclusion
\begin{itemize}
\item One layer NN and One Layer NN + RBM pre-training achieved the best results
\item Using around 4000 features from random projections and 768 hidden units worked best
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{A Literature Study of Embeddings on Source Code}

\subsection*{Metadata}

\noindent Authors: Zimin Chen, Martin Monperrus

\noindent Published: 2019

\noindent Read: 08/2020

\subsection*{Summary}
\begin{itemize}
\item Provides a literature overview of embeddings for source code tokens, functions, sequences of functions, and binary code.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item Poor paper.
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item Classifies articles as embeddings of a) tokens, b) functions, c) sets of function calls, d) binary code, d) other
\end{itemize}
Embeddings for Source Code
\begin{itemize}
\item Several works have used word2vec directly for token embeddings
\item There is rooms for research in contextual embeddings for source code
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Binary Black-box Evasion Attacks Against DL Static Malware Detectors with Adversarial Byte-Level Language Model}

\subsection*{Metadata}

\noindent Authors: Mohammadreza Ebrahimi, Ning Zhang, James Hu, Muhammad Taqi Raza, Hsinchun Chen

\noindent Published: 2020

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item MalRNN, appends bytes to the end of malware files to fool static detection systems.
\item Discusses Adversarial Example Generation (AEG) and Anti-Malware Evasion (AME).
\item Source code and dataset are supposedly available at \url{https://github.com/johnnyzn/MalRNN}, but were originally property of Microsoft.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item ``Modeling malware as a language'' (2018)
\item ``Non-negative networks against adversarial attacks'' (2019) a type of NN which is robust against adversarial examples
\item ``Deep Convolutional Malware Classifiers Can Learn from Raw Executables and Labels Only'' (2018) a simple but effective static malware detection system
\item ``Malware detection by eating a whole exe'' (2018) presumably similar to the above, but more widely cited
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item DL static malware detectors have proven successful, but can be easily fooled by adversarial examples
\item To successfully launch an adversarial malware attack, an attacker needs knowledge about the anti malware system
\item MalRNN can generate adversarial examples without knowledge of the anti malware system
\item DL malware detectors can consume raw malware binary as input and automatically extract features
\item These detectors are vulnerable to Adversarial Example Generation attacks (AEG)
\item Anti Malware Evasion (AME) seeks to use these adversarial examples to improve the model
\item One comment technique is to append bytes to the end of malware, bytes which are never executed and only confuse the anti malware system
\item This technique learns a language model on binary executables and uses them to generate benign-looking content for AME without knowledge of the anti-malware system
\end{itemize}
Related Work
\begin{itemize}
\item AEG comes in four forms
	\begin{itemize}
	\item white box - adversary has full access to attack target
	\item grey box - the attacker has access to features that are important to the classifier but parameters of NN detector not available
	\item black box - adversary has no access to attack target specs, features, or parameters, but it can obtain feedback from the attack (confidence score)
	\item binary black box - receives a binary response instead of confidence score
	\end{itemize}
\item Binary Black Box is the most common in real world applications
\item A lot of AME research uses a black box threat model, which aren't terribly realistic to real-world applications
\item Most binary black box studies target signature-based systems, thus are not hugely relevant
\item GRU alleviates the vanishing gradient problem with RNNs; sequence to sequence models allow the RNN to map different sized inputs and outputs
\end{itemize}
Proposed Method (MalRNN)
\begin{itemize}
\item goal is to evade the malware system in a binary black box threat scenario
\item MalRNN essentially injects binary sequences into binaries in an attempt to fool the classifier. \item Injects them at the end of the binary to preserve functionality
\item The LM is learned upon benign binaries, so it can learn to mimic them
\item binary executables were converted in Hex
\item Character level sequence to sequence with gated recurrent units
\item encoder decoder RNNs
\end{itemize}
Experiment and Results
\begin{itemize}
\item Compare with three well-known anti malware detectors
\item Compare with three other methods of appending bytes to the end of malware
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Modeling malware as a language}

\subsection*{Metadata}

\noindent Authors: Yara Awad, Mohamed Nassar, Haidar Safa

\noindent Published: 2018

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item Creates a ``malware language'' from disassembled malware binary opcode.
\item Models the language using word2vec and performs classification with kNN.
\item Uses a private Microsoft dataset.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item With a larger dataset, could these techniques be used to learn a BERT understanding model?
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item ``Malware Analysis and Classification: A Survey'' (2014) machine learning techniques for malware classification
\item ``Detection of Malicious Code by Applying Machine Learning Classifiers on Static Features: A state-of-the-art survey'' (2009) machine learning techniques for malware classification
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item ``Recurrent neural network for detecting malware'' (2020) various features representation including word2vec rep with RNN classifier
\item ``Automatic Malware Clustering using Word Embeddings and Unsupervised Learning'' (2019) categorizes different malware species using word2vec embeddings from system calls
\item ``Transfer Learning for Malware Multi-Classification'' (2019) evaluates the potential for transfer learning by extending a binary classifier to a multiclass task
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item Signature and heuristic based approaches only improve after unknown malware infects a system
\item Traditional ML based approaches involve feature extraction and classification
\item Dynamic analysis can still be hindered
\item This work explores static analysis via language modeling
\end{itemize}
Related Work
\begin{itemize}
\item NB classification on strings within malware, treating malware as an image vector and computing euclidian distance, analyzing function call graphs
\item Lots of work done using ngrams methodologies
\end{itemize}
Methodology
\begin{itemize}
\item Defined a malware language with concepts of what a vocabulary, word, and document are
\item Two malware languages, one where words are single assembly instructions and one where words are the instruction and an abstraction of the operands
\item Transform assembly code to conform to malware language
\item Model transformed instances using word2vec model into matrices
\item Uses kNN and word mover's distance (WMD) algorithm to perform classification
\end{itemize}
Results and Conclusions
\begin{itemize}
\item Future work should investigate the efficacy of RNNs and LSTMs
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{MalBERT: Using Transformers for Cybersecurity and Malicious Software Detection}

\subsection*{Metadata}

\noindent Authors: Abir Rahali, Moulay A. Akhloufi

\noindent Published: 2022

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item Extracts an AndroidManifest.xml metadata file from binary files with Jdax (statically/heuristically).
\item Uses BERT to model contents of this metadata file.
\item Uses the publicly available AndroZoo dataset.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item Does not actually use BERT to model the source code.
\item Terribly written.
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item ``A malware detection method based on sliding local attention mechanism'' (2020)
\item ``Robust malware detection using residual attention network'' (2020)
\item ``Ransomware classification using patch-based cnn and self-attention network on embedded n-grams of opcodes'' (2020)
\item ``Malware analysis of imaged binary samples by convolutional neural network with attention mechanism'' (2018)
\item ``Androzoo: Collecting millions of android apps for the research community'' (2016) Android malware and benignware dataset
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item 
\end{itemize}

\subsection*{Notes}

Introduction, Background, and Related Work
\begin{itemize}
\item Malware detection using BERT, first transformer based method
\item Most sequence to sequence tasks use encoder decoder with two RNNs
\item Transformers can be more efficiently parallelized and can capture long-range dependencies within sequences than RNNs
\item Mentions BERT, distilBERT, RoBERTA, and XlNet
\item Several works use DNNs and attention mechanisms to classify malware
\end{itemize}
Methodology
\begin{itemize}
\item Uses Androzoo public malware dataset
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Recurrent neural network for detecting malware}

\subsection*{Metadata}

\noindent Authors: Sudan Jha, Deepak Prashar, Hoang Viet Long, David Taniar

\noindent Published: 2020

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item Uses an RNN classifier with three feature representations: one hot encoding, random vector representation, and word2vec embeddings from disassembled malware opcode.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item A transformer or a LSTM model would probably work better...
\item Badly written
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item ``MalBERT: Malware Detection using Bidirectional Encoder Representations from Transformers'' (2021) a second `MalBERT' paper with a different MalBERT
\item ``XLCNN: pre-trained transformer model for malware detection'' (2022)
\item ``Static Malware Detection Using Stacked BiLSTM and GPT-2'' (2022)
\item ``Malware Detection Using Transformers-based Model GPT-2'' (2021)
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item Uses an RNN classifier with three feature representations: one hot encoding, random vector representation, and word2vec embeddings
\item 
\end{itemize}
Related Work
\begin{itemize}
\item
\end{itemize}
Methods
\begin{itemize}
\item
\end{itemize}
Results and Conclusions
\begin{itemize}
\item
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Malware detection with LSTM using opcode language}

\subsection*{Metadata}

\noindent Authors: Renjie Lu

\noindent Published: 2019

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item 
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item Used a strange dataset, ~1000 malware and 100 benign...work would be better if a larger set used
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item Use IDA Pro to disassemble malware into assembly, then
\item Extract opcode sequences from each assembly format file, then
\item Use word embeddings to learn features from opcode
\end{itemize}
Malware Detection Methodology
\begin{itemize}
\item Data processing
	\begin{itemize}
	\item Extracts program instructions from the .text segment of the assembly file
	\item Extracts opcode sequence using algorithm that ignores meaningless opcodes
	\end{itemize}
\item Opcode Representations in Vector Space
	\begin{itemize}
	\item Filter out infrequent opcodes to build a opcode vocab of 391
	\item Convert opcode sequence into one-hot vector...why?
	\item Use Gensim to get feature vector for opcode
	\end{itemize}
\item Feature Representation by LSTM
	\begin{itemize}
	\item Two stage LSTM can handle opcode sequences of different length
	\item Mean pooling layer after second LSTM
	\end{itemize}
\end{itemize}
Results and Conclusions
\begin{itemize}
\item 
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Malware classification with Word2Vec, HMM2Vec, BERT, and ELMo}

\subsection*{Metadata}

\noindent Authors: Aparna Sunil Kale, Vinay Pandya, Fabio Di Troia, Mark Stamp

\noindent Published: 2022

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item Experiments four different word embeddings (HMM2vec, word2vec, ELMo, and BERT) and four different classifiers (SVM, kNN, RF, and CNN) on static malware opcodes for malware classification.
\item Finds that english BERT fine-tuned on malware opcode yields the best feature representation.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item Concatenates word embeddings, when they should be added or averaged together.
\item Perhaps word2vec's poor performance is explained by this choice.
\item A structured approach such as code2vec should be considered.
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item ``Malware classification with word embedding features'' (2021) the inspiration for this work
\item ``PE header analysis for malware detection'' (2018) dataset of malware families
\item ``Malware detection using machine learning based on word2vec embeddings of machine code instructions'' (2017) malware classification using word2vec embeddings and CNNs
\item ``Malware detection using dynamic birthmarks'' (2016) malware classification using dynamic features rather than static ones
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item ML models use features such as API calls, opcode sequences, and byte n-grams
\item This work applies word embedding techniques to opcode sequences before classification with a variety of classifiers
\item  Embedding techniques include: BERT, ELMo, HMM2Vec, and word2vec
\item Generates embeddings from mnemonic opcodes
\item Opcode calls can be obtained through static analysis while API calls require dynamic analysis
\end{itemize}
Implementation
\begin{itemize}
\item Used seven malware families from a larger malware dataset
\item Extracts mnemonic opcode sequence from .exe malware sample, then uses objdump to generate .asm files from which opcode sequences can be extracted
\item Retain the $M \in \{20, 31, 40\}$ most frequent opcodes from each sequence
\item For word2vec (and the other LMs) concatenates the opcode embeddings to vectorize an example
\item Uses English BERT, but fine tunes on the malware opcodes with wordpiece tokenizer
\end{itemize}
Results and Conclusions
\begin{itemize}
\item In binary malware detection, using $M=31$ proved to be a compromise between accuracy and runtime
\item For malware family classification, BERT with SVM and kNN achieves the highest results
\item Surprisingly, word2vec classification seems to perform the worst
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{EMBER: An Open Dataset for Training Static PE Malware Machine Learning Models}

\subsection*{Metadata}

\noindent Authors: Hyrum S. Anderson, Phil Roth

\noindent Published: 2018

\noindent Read:

\subsection*{Summary}
\begin{itemize}
\item EMBER is a large (~1M) dataset composed of features extracted from binaries.
\item EMBER also comes with a tool to extract features from new binaries.
\item EMBER also comes with a Gaussian Boosted Trees model that beats MalConv
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item Using code2code to modify the byte histograms and byte-entropy of EMBER might be successful
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item ``Deep neural network based malware detection using two dimensional binary program features'' (2015) uses byte-entropy histograms in classification, which may be a good target to try and manipulate
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item
\end{itemize}
Related Work
\begin{itemize}
\item
\end{itemize}
Data Description
\begin{enumerate}
	\item Data Layout
	\begin{itemize}
		\item 
	\end{itemize}
	\item Feature Set Description: raw features provided by dataset, model features derived from dataset using hashing trick
	\begin{enumerate}
		\item Parsed Features: requires parsing PE with LIEF
		\begin{itemize}
			\item general file info: size of the file etc.
			\item header info: timestamp, target machine etc.
			\item imported functions: set of imported functions hashed into 1024 bins
			\item exported functions: hashed into 128 bins
			\item section info: name, size, entropy etc. of each section
		\end{itemize}
		\item Format Agnostic Features: do not require parsing the PE file
		\begin{itemize}
			\item Byte histogram: normalized counts of each of the 256 possible bytes present
			\item Byte-entropy histogram: sliding window entropy thing
			\item Statistical summary of string properties
		\end{itemize}
	\end{enumerate}
\end{enumerate}

\begin{itemize}
\item
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{SOREL-20M: A Large Scale Benchmark Dataset for Malicious PE Detection}

\subsection*{Metadata}

\noindent Authors:

\noindent Published:

\noindent Read:

\subsection*{Summary}
\begin{itemize}
\item A dataset containing both raw binaries and fully feature-extracted examples.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item
\end{itemize}
Related Work
\begin{itemize}
\item
\end{itemize}
Methods
\begin{itemize}
\item
\end{itemize}
Results and Conclusions
\begin{itemize}
\item
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Malware Detection by Eating a Whole EXE}

\subsection*{Metadata}

\noindent Authors: Edward Raff, Jon Barker, Jared Sylvester, Robert Brandon, Bryan Catanzaro, Charles K. Nicholas

\noindent Published: 2018

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item Proposes a novel CNN-based architecture for classifying raw malware binaries.
\item Requires sequence processing on unprecedented scales.
\item Avoids sole emphasis on the PE-header and manually extracted features.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item API calls, instructions executed, IP addresses accessed are all examples of dynamic analysis
\item Several unique challenges exist in classifying malware from raw binaries: bytes are context sensitive, relationships between byte sequences are not contiguous in the context of the entire binary, sequence classification with millions of time steps
\end{itemize}
Related Work
\begin{itemize}
\item Neural Networks for Long Sequences
\item No NN architecture has been used for sequences this long
\item Sequence processing usually involves predicting the next token in the sequence, which provides frequent feedback, unlike the task of binary classification
\item 
\end{itemize}
Model Architecture
\begin{itemize}
\item Contents of a portable executable (PE) binary can be rearranged in almost any order
\item The MS-DOS header contains pointer to the PE-Header, which in turn contains pointers to all other portions of the executable
\item CNN can capture the invariance between the various important features of the binary
\item Uses an embedding layer to map bytes values to fixed length before applying convolutions
\end{itemize}
Results and Conclusions
\begin{itemize}
\item Required 8 GPUs (due to memory constraints) and a month of training for two million samples
\item This model may have avoided learning an association between packing and malware, which will be helpful to reduce false positives
\item Batch normalization led to poor performing models, because the malware binaries did not follow a normal distribution
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Adversarial Examples for Malware Detection}

\subsection*{Metadata}

\noindent Authors: Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes, Patrick McDaniel 

\noindent Published: 2017

\noindent Read: 08/2020

\subsection*{Summary}
\begin{itemize}
\item Modifies an algorithm from CV to minimally modify a malware sample's feature representation to fool malware classifier.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item ``The limitations of deep learning in adversarial settings'' (2016) discusses adversarial approaches to DL
\item ``Generating adversarial malware examples for black-box attacks based on GAN'' (2017) malware approach for generating adversarial samples based upon GANs
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item ``Adversarial Malware Binaries: Evading Deep Learning for Malware Detection in Executables'' (2018) 
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item ML algorithms can be fooled by minor perpetuations in examples
\item Malware has less options for where to make the perpetuations than in other domains such as image classification
\item Approach generalizes to any malware detection system using a differentiable classification function
\end{itemize}
Methods
\begin{itemize}
\item Uses statically determined sparse binary features with a basic MLP
\item Essentially seeks to change the minimal number of bits in the feature rep until the system is fooled
\item Is careful when modifying the malware to ensure that it is still functional afterwards
\item Uses the Drebin Dataset
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN}

\subsection*{Metadata}

\noindent Authors: Weiwei Hu and Ying Tan

\noindent Published: 2017

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item Proposes MalGAN, a GAN-based adversarial malware creator.
\item Uses GANs to modify the bits of an API-call binary malware feature vector.
\item Highly effective against several black box malware detectors.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item Authors used a discrete malware representation, so could not use some adversarial methods from CV.
\item Adversarial malware modification for continuous feature representation using CV (continuous) methods?
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item ``Adversarial perturbations against deep neural networks for malware classification'' (2016) the gradient based approach to generate adversarial Android malware examples
\item ``Generative adversarial nets'' (2014) hugely cited work
\item ``Explaining and harnessing adversarial examples'' (2014) a gradient based algorithm to generate adversarial examples 
\item Defense from Adversarial Attacks
	\begin{itemize}
	\item ``To- wards deep neural network architectures robust to adversarial examples'' (2014) auto-encoders approach
	\item ``Distillation as a defense to adversarial perturbations against deep neural networks'' (2016) defensive distillation
	\item ``A general retraining framework for scalable adversarial classification'' (2016) retraining
	\item ``Evaluation of defensive methods for DNNs against multiple adversarial evasion models'' (2016) overview of defensive methods
	\end{itemize}
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item ``Evading Anti-Malware Engines With Deep Reinforcement Learning'' (2019)
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item Malware authors usually can only perform black box or binary black box attacks
\item Previous work has used gradient-based approaches, a sub model to mitigate disadvantages of black box scenario, 
\item Malware authors can determine some information about the features the system uses by feeding it carefully selected examples
\item This work assumes malware authors can figure out the features the detection system uses
\end{itemize}
MalGAN
\begin{itemize}
\item Generates adversarial examples for binary API features because they are widely used
\item Only adds API calls to the feature vector since removing them may crack the malware
\item Uses a basic feed forward NN as a substiute detector to classify the generator
\item Trains the sub detector on same data as black box detector, but to ``fit'' the black box detector, uses the black box detector's predictions as labels for ground truth
\end{itemize}
Results and Conclusions
\begin{itemize}
\item Used data from \url{https://malwr.com/}
\item Most adversarial techniques are for CV
\item CV features are continuous, while this malware feature choice is binary
\item MalGAN outperforms gradient based approaches that used a white box scenario
\item Retraining the black box detector on adversarial examples diminishes the effect of MalGAN, but then malware authors could simply retrain MalGAN again
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Adversarial Perturbations Against Deep Neural Networks for Malware Classification}

\subsection*{Metadata}

\noindent Authors: Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes, Patrick McDaniel

\noindent Published: 2016

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item Modifies an existing gradient-based approach to generate adversarial malware in a white box setting.
\item Investigates methods for hardening DNNs against adversarial malware and finds retraining to be most successful.
\item 
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item ``Practical black-box attacks against deep learning systems using adversarial examples'' (2016) black-box scenario for adversarial attacks
\item ``The security of machine learning'' (2010) broad overview of attacks against machine learning systems
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item Compared to CV, malware domain has two major differences: continuous, differentiable input is replaced with discrete input, and the malware must remain functional following modification
\item Uses the Drebin dataset and the gradient-based method from [17]
\item Employs the following constraints on adversarial generation:
	\begin{itemize}
	\item only add/remove features
	\item preserve function of malware
	\item only add a restricted amount of features, particularly to the AndroidManifest.xml file
	\end{itemize}
\item Explores methods of hardening DNNs against adversarial malware:
	\begin{itemize}
	\item feature reductions
	\item distillation (training with class probabilities instead of binary labels)
	\item retraining
	\end{itemize}
\end{itemize}
Related Work
\begin{itemize}
\item
\end{itemize}
Methods
\begin{itemize}
\item Uses sparse binary features to represent malware
\item Essentially changes one bit of the feature vector at a time until the classifier is fooled
\item Distillation uses probability outputs from a classifier to train a second classifier instead of class labels
\end{itemize}
Results and Conclusions
\begin{itemize}
\item
\end{itemize}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Automated poisoning attacks and defenses in malware detection systems: An adversarial machine learning approach}

\subsection*{Metadata}

\noindent Authors: Sen Chen, Minhui Xue, Lingling Fan, Shuang Hao, Lihua Xu, Hao Zhu, Bo Li

\noindent Published: 2018

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item Explores defense of poisoning attacks.
\item Creates an adversarial malware system and fools three state of the art detectors.
\item Uses similarity-based filtering to identify potentially adversarial examples and build a more robust system.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item Malware authors can actually attempt to alter the training data of malware detection systems themselves
\item Poisoning attack: attacker assumes control of a subset of training samples
\item Introduces camouflage detection, which uses similarity analysis to attempt to identify adversarial examples
\item Dataset from Contagio Mobile Website
\end{itemize}
Related Work
\begin{itemize}
\item
\end{itemize}
Methods
\begin{itemize}
\item
\end{itemize}
Results and Conclusions
\begin{itemize}
\item
\end{itemize}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Arms Race in Adversarial Malware Detection: A Survey}

\subsection*{Metadata}

\noindent Authors: Deqiang Li, Qianmu Li, Yanfang (Fanny) Ye, Shouhuai Xu

\noindent Published: 2021

\noindent Read: 08/2022

\subsection*{Summary}
\begin{itemize}
\item Performs a systematic/mathematical overview of Adversarial Malware Defense.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item The evasion attack is much more extensively studied than the poisoning attack.
\item Vastly more complicated than it needs to be and completely bogged down with mathematics.
\item Has useful suggestions for potential future work.
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item ``Prudent practices for designing malware experiments: Status quo and outlook.'' (2012) advice on how to conduct malware research effectively and ethically
\item ``Deceiving end- to-end deep learning malware detectors using adversarial examples'' (2018) evasion attacks against MalConv using gradient optimization
\item Poisoning attacks:
	\begin{itemize}
	\item ``The security of machine learning'' (2010)
	\item ``Poisoning attacks against support vector machines'' (2012)
	\item ``Security evaluation of support vector machines in adversarial environments'' (2014)
	\item ``Towards poisoning of deep learning algorithms with back-gradient optimization'' (2017)
	\item ``Label sanitization against label flipping poisoning attacks'' (2018)
	\item ``Automated poisoning attacks and defenses in malware detection systems: An adversarial machine learning approach'' (2018)
	\item When does Machine Learning FAIL? Generalized Transferability for Evasion and Poisoning Attacks'' (2018)
	\item ```Why do Adversarial Attacks Transfer? Explaining Transferability of Evasion and Poisoning Attacks'' (2019)
	\end{itemize}
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item ``Adversarial Attacks against Windows PE Malware Detection: A Survey of the State-of-the-Art'' (2021)
\end{itemize}

\subsection*{Notes}

\noindent Introduction
\begin{itemize}
\item Surveys adversarial malware detection through the lens of a unified conceptual framework of assumptions based upon assumptions, attacks, defenses, and security properties
\item Evasion vs poisoning adversarial machine learning (AML) attacks
\item Adversarial Malware Detection (AMD) [16, 27, 36, 39, 40, 53, 114, 118, 127, 133, 134]
\item Three differences to AMD vs AML: no standard feature definitions, feature definitions are often discrete, and malware functionality must be preserved
\end{itemize}

\noindent 2. Survey and Systematization Methodology 
\begin{enumerate}
\item Brief Review on ML-based Malware Detection
	\begin{enumerate}
	\item Features can be handcrafted or learned or both
	\item Two kinds of features: static features (API calls, strings, etc.) and dynamic features (instructions, registry activities)
	\item Case studies: The Drebin Malware Aetector, The MalConv Malware Detector
	\end{enumerate}
\item Framework
	\begin{enumerate}
	\item Systemizing Assumptions:
		\begin{enumerate}
		\item IID: assumes train/test files are Independently Identically Distributed (IID)
		\item Oracle Assumption: there is an oracle that can tell if two files are have the same functionality
		\item Measurability Assumption: there is a way to measure the manipulations to transform one file to another
		\item Smoothness Assumption: 
		\item Invertibility Assumption: feature extraction is invertible, or partially invertible with side-effects
		\end{enumerate}
	\item Systemizing Attacks:
		\begin{enumerate}
		\item Attacker's Objective: indiscriminate (cause false negatives), targeted (cause specific false negatives), availability (cause unsustainable false positives)
		\item Attacker's Input (attacker may have some knowledge of A1-A5 and total knowledge of A6-A10):
			\begin{enumerate}
			\item $A_1$: classifier's training set
			\item $A_2$: classifier's techniques, e.g., ensemble learning, weight regularization (regularization/dropout), adversarial training, verifiable learning (overestimate error of perturbations, then minimize them), robust features (selection), input transformation (non learning methods such as de-obfuscation), classifier randomization (a random subset of an ensemble to prevent attacker from learning about the classifier), sanitizing examples (detect adversarial examples) 
			\item $A_3$: knowledge of feature set
			\item $A_4$: knowledge of training algorithm
			\item $A_5$: knowledge of classifier's responses/outputs to samples
			\item $A_6$: the perturbations the attacker can make
			\item $A_7$: attack tactics, e.g., basic evasion, optimal evasion 1 (attempts to minimize the perturbations in evasion), and optimal evasion 2 (attempts to maximize the classifier's loss and create a high confidence attack), basic poisoning, optimal poisoning (maximizes loss of surrogate classifier for high-confidence attack)
			\item $A_8$: attack techniques, e.g., Gradient-based Optimization (), Sensitive Features (inject/remove features to decrease classification error), Mimicry (mimics benign sample), Transferability (train surrogate model), Heuristic Search (does not need invertibility assumption), Generative Model (create adversarial malware vectors with generative model then invert into malware), and Mixture Strategy (combination of techniques)
			\item $A_9$: corresponds to the attacker's available possible adversarial files
			\end{enumerate}
		\end{enumerate}
	\item Systemizing Defenses:
		\begin{enumerate}
		\item Defender's Objectives: goal is to detect malicious files (adversarial/normal) with minimal FPs
		\item Defender's Inputs: the defenders knowledge of $A_1, \dots, A_9$
		\end{enumerate}
	\end{enumerate}
	\item Systemizing Security Properties
		\begin{enumerate}
		\item Representation Robustness: similar files have similar reps
		\item Classification Robustness: similar reps have same classifications
		\item Detection Robustness: feature extraction returns similar reps for files with the same functionality
		\item Training Robustness: small changes in training set do not change classifier much
		\end{enumerate}
\end{enumerate}

\noindent Systemizing AMD Arms Race
\begin{enumerate}
\item Systematizing Attack Literature
	\begin{enumerate}
	%\item Attacks Using GO:
	%\item Attacks Using SF:
	%\item Attacks Using MI:
	%\item Attacks Using TR:
	%\item Attacks Using HS:
	%\item Attacks Using GM:
	%\item Attacks Using MS:
	%\item Drawing Observations and Insights. 
	\item Most studies focus on indiscriminate attacks, evasion attacks
	\item Oracle assumption widely made
	\item Knowing defender's feature set is critical for transfer attacks
	\item Evasion attacks are most effective when given freedom to perform large variety of manipulations
	\end{enumerate}
\item Systematizing Defense Literature
	\begin{enumerate}
	%\item Defenses Using EL
	%\item Defenses Using WR
	%\item Defenses Using AT
	%\item Defenses Using Verifiable Learning (VL)
	%\item Defenses Using RF
	%\item Defenses Using IT
	%\item Defenses Using CD
	%\item Defenses Using SE
	%\item Drawing Observations and Insights:
	\item Most studies focus on black-box defenses, evasion attacks
	\item There is no perfect defense against evasion/poisoning attacks
	\item Sanitizing adversarial files is effective against black/grey box attacks, but not white box
	\item Effective defenses often require the defender know the attacker's manipulation set, which is unrealistic in real world scenarios
	\item The effectiveness of adversarial training depends on the defenders ability to identify the most powerful attack
	\end{enumerate}
\item Systematizing AMD Arms Race
	\begin{enumerate}
	\item Arms race in PDF malware detection, PDFrate
	\item Arms race in android malware detection, Drebin
	\item Arms race in DNN-based malware detection, MalConv
	\end{enumerate}
\end{enumerate}

\noindent Future Research Directions
\begin{itemize}
\item Pinning down the causes of adversarial malware examples
\item Characterizing the relationship between transferability and vulnerability, ie, the relationship between how knowledge gained from a surrogate model influences a systems vulnerability
\item Investigating adversarial malware examples in the wild
\item Quantifying the robustness and resilience of malware detectors
\item Designing malware detectors with provable robustness and resilience guarantees (RF robust features [141], AL (Adversarial Training [53] or Ensemble Learning [142]), VL verifiable learning ie intentionally overestimate the error from the attacker [130])
\end{itemize}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Adversarial Deep Learning for Robust Detection of Binary Encoded Malware}

\subsection*{Metadata}

\noindent Authors: Abdullah Al-Dujaili, Alex Huang, Erik Hemberg, Una-May O‚ÄôReilly

\noindent Published: 2018

\noindent Read: 08/22

\subsection*{Summary}
\begin{itemize}
\item Modifies gradient-based adversarial approach to modify malware binary files.
\item Uses binary features of API calls present in malware.
\item Develops SLEIPNIR, a robust training approach to adversarial malware.
\item Uses an open source malware dataset of 35k malware and 20k benign.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item Most adversarial malware work seems to assume that the input domain (features) are discrete rather than continuous.
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item ``Deep neural network based malware detection using two dimensional binary program features'' (2015) DNN malware detection with two dimensional binary PE program features
\item ``Explaining and harnessing adversarial examples'' (2014) FGSM adversarial generation white box attack, as well as general background about adversarial ML
\item ``Towards deep learning models resistant to adversarial attacks'' (2017) original authors of saddle-based AE defense training
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item ``Adversarial Deep Ensemble: Evasion Attacks and Defenses for Malware Detection'' (2020)
\item ``Adversarial Examples for CNN-Based Malware Detectors'' (2019)
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item Presents four methods to create adversarial examples (AEs)
\item Presents the SLEIPNIR framework for training adversarial malware detectors
\item Source code and dataset available here \url{https://github.com/ALFA-group/robust-adv-malware-detection}
\end{itemize}
Related Work
\begin{itemize}
\item Adversarial approach Fast Gradient Sign Method FGSM finds the direction that moves the outputs of NN the most and most the inputs along this direction
\end{itemize}
Methods
\begin{itemize}
\item
\end{itemize}
Results and Conclusions
\begin{itemize}
\item
\end{itemize}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Deep Neural Network Based Malware Detection Using Two Dimensional Binary Program Features}

\subsection*{Metadata}

\noindent Authors: J Saxe, K Berlin

\noindent Published: 2015

\noindent Read: 08/22

\subsection*{Summary}
\begin{itemize}
\item One of the earlier works on DNN malware detection.
\item Uses a slightly unconventional set of features.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item 
\end{itemize}
Related Work
\begin{itemize}
\item 
\end{itemize}
Methods
\begin{itemize}
\item Feature Engineering
	\begin{itemize}
	\item 2D byte histogram features are essentially slices of the base-2 entropy every 1024 bits
	\item Uses counts of PE imported DLLs but hashes them into 256 bins (does not avoid collisions)
	\item PE metadata and string features as well
	\end{itemize}
\end{itemize}
Results and Conclusions
\begin{itemize}
\item
\end{itemize}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Adversarial Deep Ensemble: Evasion Attacks and Defenses for Malware Detection}

\subsection*{Metadata}

\noindent Authors: Deqiang Li and Qianmu Li

\noindent Published: 2020

\noindent Read: 08/22

\subsection*{Summary}
\begin{itemize}
\item Uses an ensemble of DNNs in malware detection and an mixture of attack strategies in adversarial malware generation.
\item The ensemble proves more effective at malware identification and the mixed attack strategies downgrade the performance of VirusTotal.
\item Uses discrete input domain features.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item Cited in reference to perturbing the element in the feature space rather than the file space:
	\begin{itemize}
	\item ``Practical evasion of a learning-based classifier: A case study'' (2014)
	\item ``Why do adversarial attacks transfer? Explaining transferability of evasion and poisoning attacks'' (2019)
	\item ``Yes, machine learning can be more secure! A case study on Android malware detection'' (2019)
	\item ``Intriguing properties of adversarial ML attacks in the problem space'' (2019)
	\end{itemize}
\item ``Adversarial training and robustness for multiple perturbations'' (2019) the so-called max attack
\item ``Towards the first adversarially robust neural network model on MNIST'' (2018) salt and peppering, pointwise attack
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item Ensembles have been used in adversarial attacks and adversarial defense
\item Proposes \textit{mixture of attacks}, which lets attackers use multiple generative methods to make adversarial malware
\end{itemize}
Related Work
\begin{itemize}
\item Ensemble Attacks for improving effectiveness of AEs
	\begin{itemize}
	\item Attacking multiple classifiers can improve the transferability of AEs
	\item Deploying multiple attacks can entirely circumvent a DNNs defenses
	\end{itemize}
\item Ensemble Defenses
	\begin{itemize}
	\item 
	\end{itemize}
\end{itemize}
Preliminaries
\begin{itemize}
\item Two types of evasion attacks: perturbations in the file space and perturbations in the feature space
\item Perturbations in the feature space must be invertible, that is, one must be able to figure out how to modify the file in order to achieve the change in the feature space
\item This file modification could perturb the feature rep in extra, unintentional ways, but experimentally, this does not appear to be a big issue
\item Attack strategies in literature include gradient-based attacks (white box), gradient free (grey box) eg salt/pepper [18] and pointwise [18]
\end{itemize}
Methods
\begin{itemize}
\item
\end{itemize}
Results and Conclusions
\begin{itemize}
\item
\end{itemize}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{A Framework for Enhancing Deep Neural Networks Against Adversarial Malware}

\subsection*{Metadata}

\noindent Authors: Deqiang Li; Qianmu Li; Yanfang Ye; Shouhuai Xu

\noindent Published: 2021

\noindent Read: 08/22

\subsection*{Summary}
\begin{itemize}
\item Proposes six guiding principles for malware detection systems, ultimately, an ensemble of classifiers, each hardened via an input transformation, adversarial training, and semantic-preserving techniques.
\item Throughly tests the attack with twenty different attack types.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item Actually recommends binarizing any continuous features so they are more robust to perturbations.
\item Future work: how should graph-based or sequential-like feature reps be accommodated?
\end{itemize}

\subsection*{Cited}
\begin{itemize}
\item ``Intriguing properties of adversarial ml attacks in the problem space'' (2020) the problem of adversarial malware examples are much less investigated
\item ``When a tree falls: Using diversity in ensemble classifiers to identify evasion in malware detectors'' (2016) RF confidence scores to detect adversarial malware
\item ``HashTran-DNN: A. framework for enhancing robustness of deep neural networks against adversarial malware samples'' (2018) detecting adversarial malware examples using DAE
\item ``Yes, machine learning can be more secure! A case study on android malware detection'' (2019)
\item `The random subspace method for constructing decision forests'' (1998) ensembling method for sparse features
\item ``Gotcha - sly malware!: Scorpion a metagraph2vec based malware detection system'' (2018) malware detection with graph-based feature representation
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item ``Deep Learning for Android Malware Defenses: a Systematic Literature Review'' (2022)
\item ``Malware Analysis by Combining Multiple Detectors and Observation Windows'' (2021)
\item ``Ensemble dynamic behavior detection method for adversarial malware'' (2022)
\end{itemize}

\subsection*{Notes}

Introduction
\begin{itemize}
\item Proposes six guiding principles to enhance robustness of DNNs
\item Validates the effectiveness of the framework against grey and whitebox attacks
\item Achieves highest score in MIT Lincoln Lab challenge
\item Code publicly available at \url{https://github.com/deqangss/aics2019_ challenge_adv_mal_defense}
\end{itemize}
Related Work
\begin{itemize}
\item Ensemble Learning can improve a system's resilience to adversarial examples
\item Input Preprocessing transforms input to difference representation, which can reduce the impact of perturbations applied to the original input, e.g., feature squeezing [25]
\item Adversarial Training add adversarial examples to the training data, but may only be effectives for the specific kind of adversarial evasion attack methods the training data is augmented with
\item Denoising Auto-Encoder (DAE) Representation Learning learns robust representations that may be less sensitive to perturbations
\end{itemize}
Adversarial Malware Attacks
\begin{itemize}
\item Random Attack (baseline): attacker randomly modifies feature at each iteration
\item Mimicry Attack (AMD): perturb malware to mimic a benign examples
\item FGSM Attack (CV): perturb feature vector in the direction of the norm of the gradients of the loss function
\item Grosse Attack (AMD): manipulate absence of sensitive feature into presence of the feature
\item BGA/BCA Attacks (AMD): increases binary features values from 0 to 1 based upon behavior of gradients
\item PGD Attack (CV): supports feature addition and feature removal via gradient methods
\end{itemize}
Adversarial Malware Defense
\begin{itemize}
\item Guiding Principles:
	\begin{enumerate}
	\item Knowing the Enemy: attempt to know as much about incoming attacks as possible
	\item Bridging Grey-Box vs White Box: in grey box scenario, attacker can train a surrogate classifier $f'$ to mimic the classifier $f$, so defense in grey box scenario is essentially the same as defense in white box
	\item Ensembling
	\item Transformations Against Perturbations: binarize discrete features in binary ones to reduce impact of perturbations
	\item Using Vaccine: use minimax adversarial training to harden models
	\item Preserving Semantics: malware must remain functional after perturbations, so focussing on the import features of the malware should preserve classifier functionality. Using an encoder-decoder, such as DAE, can help with this.
	\end{enumerate}
\item Create an ensemble of classifiers, each hardened via binarization, adversarial training, and de-noising auto encoder.
\end{itemize}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Gotcha - Sly Malware!: Scorpion A Metagraph2vec Based Malware Detection System}

\subsection*{Metadata}

\noindent Authors: Yujie Fan, Shifu Hou, Yiming Zhang, Yanfang Ye, Melih Abdulhayoglu

\noindent Published: 2018

\noindent Read: 08/22

\subsection*{Summary}
\begin{itemize}
	\item Models malware content-based and relationship-based features in network structures, generates embeddings for them, then learns an SVM classifier
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item Work could be improved upon by using higher dimensional embeddings and a more potent classifier
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item - ``Combining file content and file relations for cloud based malware detection'' (2011) authors previous work, which uses HIN, but not the meta-graph 
	\item Content Based Feature Approaches
	\begin{itemize}
		\item ``Adversarial Machine Learning in Malware Detection: Arms Race between Evasion Attack and Defense'' (2017)
		\item ``Malicious sequential pattern mining for automatic malware detection'' (2016)
		\item ``Malware detec- tion with quantitative data flow graphs'' (2014)
		\item ``DeepAM: a heterogeneous deep learning framework for intelligent malware detection'' (2018)
	\end{itemize}
	\item Relationship Based Feature Approaches
	\begin{itemize}
		\item ``Polonium: Tera-scale graph mining for malware detection'' (2010)
		\item ``Analyzing file-to-file relation network in malware detection'' (2015)
		\item ``Intelligent malware detection based on file relation graphs'' (2015)
		\item ``FindMal: A file-to-file social network based malware detection framework'' (2016)
		\item ``Guilt by association: large scale malware detection by mining file-relation graphs'' (2014)
	\end{itemize}
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item ``alpha-Cyber: Enhancing Robustness of Android Malware Detection System against Adversarial Attacks on Heterogeneous Graph based Model''
\item ``Sok: Arms race in adversarial malware detection''
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{enumerate}
	\item Uses a heterogeneous information network (HIN) and a meta-graph to represent content and relation-based features in malware
	\item Learns low dimensional representations for nodes in HIN
	\end{enumerate}
	System Architecture
	\begin{enumerate}
		\item Data Collector
		\item Feature Extractor: extracts content-based and relation-based features
		\item Meta Graph Builder HIN: structural HIN models relationships between entities and meta graphs are built from the HIN
		\item Metagraph2vec: learns low dimensional feature representations from metagraph
		\item Malware Detector: uses SVM to classify from latent features
	\end{enumerate}
	\item Proposed Method
	\begin{enumerate}
		\item Feature Extraction
		\begin{itemize}
			\item Content-based features: extract windows API calls from Import Tables
			\item Relation-based features: binary matrices where 1 represents the relationship is present between the ith and jth element
			\begin{itemize}
				\item R1: file-replace-archive matrix $R$
				\item R2: file-exist-machine matrix $E$
				\item R3: file-create-file matrix $C$
				\item R4: file-include-API matrix $I$
				\item R5: API-belongto-DLL matrix $B$
			\end{itemize}
		\end{itemize}
		\item Meta-graph Based Relatedness
		\begin{itemize}
			\item A HIN is a graph with an entity type mapping $V \rightarrow A$ and a relationship type mapping $E \rightarrow R$, where $A$ are the valid entities, $R$ are the valid relationships, and the network schema is a graph $T_G = (A, R)$
			\item $A = $ \{ PE file, archive, machine, API, DLL \}
			\item $R = \{R_1, R_2, R_3, R_4, R_5\}$
			\item A meta-graph is a DAG defined on a HIN
			\item Traditional relationship learning typically factors the adjacency matrix of the meta-graph, which is computationally intensive
		\end{itemize}
		\item Metagraph2vec
		\begin{itemize}
			\item HIN Rep Learning attempts to map each vertex in a HIN to a vector
			\item first, meta-graph guided random walk is proposed to map the word-context concept in a text corpus into a HIN
			\item then skip-gram is utilized to learn effective node representation for a HIN
			\item finally, a multi-view fusion algorithm is proposed to incorporate different node representations learned based on different meta-graph schemes.
		\end{itemize}
	\end{enumerate}
	\item Results and Conclusions
	\begin{enumerate}
	\item Uses data from Comodo Cloud Security Center
	\end{enumerate}
	\item Related Work
	\begin{enumerate}
		\item Most malware detection uses either content based features or relation based features
	\end{enumerate}
\end{enumerate}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{A survey on practical adversarial examples for malware classifiers}

\subsection*{Metadata}

\noindent Authors: Daniel Park, B√ºlent Yener

\noindent Published: 2020

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Reviews literature on adversarial malware techniques that preserve the functionality of the malware.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
\item A big problem with adversarily modifying malware is maintaining functionality. Using code-understanding tools could allow an attacker to add code blocks that don't actually execute.
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item ``Intriguing Properties of Adversarial ML Attacks in the Problem Space'' (2020) discusses the difficulty of the inverse transform from feature rep to malware
	\item ``Generic Black-Box End-to-End Attack Against State of the Art API Call Based Malware Classifiers'' (2018) GADGET adds API calls to malware
	\item ``Deceiving Portable Executable Malware Classifiers into Targeted Misclassification with Practical Adversarial Examples'' (2020) add bogus code blocks and other interesting features
	\item ``HideNoSeek: Camouflaging Malicious JavaScript in Benign ASTs'' (2019) uses ASTs in AM generation
	\item ``Learning to Evade Static PE Machine Learning Malware Models via Reinforcement Learning'' (2018)
	\item Surveys:
	\begin{itemize}
		\item ``Adversarial Examples: Attacks and Defenses for Deep Learning''
		\item ``Towards Adversarial Malware Detection: Lessons Learned from PDF-Based Attacks'' (2019)
		\item ``A Survey On Automated Dynamic Malware Analysis Evasion and Counter-Evasion: PC, Mobile, and Web'' (2017)
		\item ``A Survey on Malware Detection Using Data Mining Techniques'' (2017)
		\item ``Survey of machine learning techniques for malware analysis'' (2019)
	\end{itemize}
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Focuses on literature that generates functional malware executables, rather than those that just generate challenging features
	\end{itemize}
	\item Background
	\begin{enumerate}
		\item ML for Malware
		\begin{itemize}
			\item Static features include: bytes, opcodes, API calls, system calls, and environment info
			\item Dynamic features include: opcodes, API calls, systems calls, and environment info extracted during execution
		\end{itemize}
		\item Adversarial examples
		\begin{itemize}
			\item Threat Model: threat vector and surface (means the adversary interacts with the model), knowledge, and capabilities
		\end{itemize}
	\end{enumerate}
	\item Practical Attacks
	\begin{enumerate}
		\item Gradient-based Approaches
		\begin{itemize}
			\item Editing Bytes and metadata (all require white box except GADGET)
			\item Code transformations
		\end{itemize}
		\item Problem-driven Approaches
		\begin{itemize}
			\item Editing Bytes and metadata
			\item Code transformations
		\end{itemize}
		\item Problem-driven Approaches
		\begin{itemize}
			\item 
		\end{itemize}
	\end{enumerate}
	\item Research Directions
	\begin{itemize}
		\item Defending against practical malware examples: smoothing [2] and randomization [60] for AMD 
		\item Relationships between obfuscated and adversarial examples
		\item Integration of static and dynamic analysis techniques
	\end{itemize}
\end{enumerate}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Deceiving Portable Executable Malware Classifiers into Targeted Misclassification with Practical Adversarial Samples}

\subsection*{Metadata}

\noindent Authors: Yunus Kucuk, Guanhua Yan

\noindent Published: 2020

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Trains three RF classifiers using opcode frequencies, API function imports, and system calls extracted from dynamic analysis
	\item Uses genetic algorithms to create adversarial examples for each classifier: adding bogus code block, obfuscating API calls, and adding API calls to modify system call usage
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item RF would probably be inherently more robust to adversarial attacks than DNNs.
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item ``Learning to evade static PE machine learning malware models via reinforcement learning'' (2018)
	\item ``Obfuscator-LLVM - software protection for the masses'' (2015)
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item ``A Unified Framework for Adversarial Attack and Defense in Constrained Feature Space'' (2022)
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Trains three RF classifiers using opcode frequencies, API function imports, and system calls extracted from dynamic analysis
		\item Develops techniques that fool each type of classifier
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item Malware Dataset and Classifiers
	\begin{itemize}
		\item Opcode n-gram features are attained by disassembling binaries (IDA Pro)
		\item API function features are binary vectors extracted from the .idata section of the PE
		\item System call feature vectors counts of how often each call is made during dynamic execution
	\end{itemize}
	\item Deceiving the Opcode Classifier
	\begin{itemize}
		\item Essentially add bogus code hidden behind if statements that never execute
		\item Carefully monitors the changes in the feature vector
	\end{itemize}
	\item Deceiving the API Classifier
	\begin{itemize}
		\item Performs API obfuscation
	\end{itemize}
	\item Deceiving the System Call Classifier
	\begin{itemize}
		\item Adds API calls to increase the counts of specific system calls
	\end{itemize}
	\item Conclusions
	\begin{itemize}
		\item Only uses three RF classifiers, when in reality, a diverse ensemble would be most practical
		\item Only uses genetic algorithms to create adversarial examples
	\end{itemize}
\end{enumerate}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Adversarial Attacks against Windows PE Malware Detection: A Survey of the State-of-the-Art}

\subsection*{Metadata}

\noindent Authors: Xiang Ling, Lingfei Wu, Jiangyu Zhang, Zhenqing Qu, Wei Deng, Xiang Chen, Chunming Wu, Shouling Ji, Tianyue Luo, Jingzheng Wu, Yanjun Wu

\noindent Published: 2022

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Three main challenges: format-preserving, executability-preserving and maliciousness-preserving
	\item Black box attacks in the problem space are theoretically the most model agnostic
	\item These attacks use creative methods to generate the examples, such as genetic algorithms, RL, GANs, etc.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item Research on attacks should be focused on the black box problem space scenario.
	\item Identify problematic sequences of opcode and replace them with computationally equivalent ones to fool detector?
	\item Adversarial Malware needs to be verified for correctness in Cuckoo Sandbox
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item Surveys for NLP, Graphs, and CV:
	\begin{itemize}
		\item ``Improving the reliability of deep neural networks in NLP: A review'' (2020)
		\item ``Adversarial attack and defense on graph data: A survey'' (2018)
		\item ``Threat of adversarial attacks on deep learning in computer vision: A survey'' (2018)
	\end{itemize}
	\item ``Misleading authorship attribution of source code using adversarial learning'' (2019) discusses feature-space to problem-space dilemma
	\item Then, the authors employ an interpretation model of SHAP [85] to assign each n-gram feature with an importance value and observe that the 4-gram ‚Äúmove + and + or + move‚Äù feature is a typical malicious feature as it almost does not appear in the benign PE samples. COULD this be used for poisoning attacks??????? Also deploys a substitution method 
	\item ``An Adversarial Machine Learning Method Based on OpCode N-grams Feature in Malware Detection'' (2020) authors substitute blocks of opcode for computationally equivalent blocks of opcode
	\item Changes API call sequence:
	\begin{itemize}
		\item ``Black-box attacks against RNN based malware detection algorithms'' (2017)  generative RNNs
		\item ``Generic black-box end-to-end attack against state of the art API call based malware classifiers'' (2018) GADGET
		\item ``Query-Efficient Black-Box Attack Against Sequence-Based Malware Classifiers'' (2020) BADGER builds upon GADGET
	\end{itemize}
	\item Black Box - Problem Space Attacks:
	\begin{itemize}
		\item Reinforcement Learning
		\begin{itemize}
			\item \xout{``Evading anti-malware engines with deep reinforcement learning''} (2019)
			\item ``DeepDetectNet vs RLAttackNet: An adversarial method to improve deep learning-based static malware detection model'' (2020)
			\item ``An IRL-based malware adversarial generation method to evade anti-malware engines'' (2021)
			\item ``Generating adversarial examples for static PE malware detector based on deep reinforcement learning'' (2020)
			\item ``Binary Black-Box Attacks Against Static Malware Detectors with Reinforcement Learning in Discrete Action Spaces.'' (2021)
			\item ``AIMED-RL: Exploring Adversarial Malware Examples with Reinforcement Learning''
			\item ``Enhancing machine learning based malware detection model by reinforcement learning'' (2018)
		\end{itemize}
		\item Evolutionary Algorithms
		\begin{itemize}
			\item ``AIMED: Evolving Malware with Genetic Programming to Evade Detection'' (2019)
			\item ``ARMED: How Automatic Malware Modifica- tions Can Evade Static Detection'' (2020)
			\item ``Functionality-preserving Black-box Optimization of Adversarial Windows Malware'' (2020) GAMMA
			\item ``MDEA: Malware Detection with Evolutionary Adversarial Learning'' (2020)
		\end{itemize}
		\item GANs
		\begin{itemize}
			\item ``Black-Box Adversarial Attacks Against Deep Learning Based Malware Binaries Detection with GAN'' (2020) GAPGAN 
			\item ``MalFox: Camouflaged Adversarial Malware Example Generation Based on C-GANs Against Black-Box Detectors'' (2020)
		\end{itemize}
	\end{itemize}
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Malware is highly structured, unlike images, which makes it difficult to make adversarial approaches preserve the functionality of malware
		\item Three big challenges: format-preserving, executability-preserving and maliciousness-preserving
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item ML and DL for PE Malware Detection
	\begin{enumerate}
		\item PE file Layout and Malware
		\begin{itemize}
			\item Contains header information (tells OS how to map the PE file into memory), section information (executable code and associated data), and un-mapped data (chunks of un-used bytes)
		\end{itemize}
		\item Learning Framework for PE Malware Detection
		\begin{itemize}
			\item PE malware usually not publicly released
			\item Static features include: byte sequences (raw bytes, n-grams of bytes, etc.), readable strings (file names, IP-addresses, etc.), header information (file statistics, imported/exported functions, etc.), greyscale image (bytes to image)
			\item Dynamic features include: system resource status, file status, registry status, network status
			\item Hybrid features include (can be extracted statically or dynamically): opcode, system calls, API calls, control flow graph (CFG), function call graph 
		\end{itemize}
	\end{enumerate}
	\item Challenges of Adversarial Attacks for PE Malware
	\begin{enumerate}
		\item General concept and Taxonomy
		\begin{itemize}
			\item Feature space attack: minimize the difference between an adversarial example and its original counterpart \textit{in the feature space, $\mathbb{X}$} such that it is misclassified: $\min_{x'} \textrm{ distance}(x', x) \textrm{ s.t. } x' \in \mathbb{X}, f(x') = y' \neq y$
			\item Problem space attack: how to modify the real-world examples with minimal cost \textit{in the problem space, $\mathbb{Z}$} such that the it is misclassified: $\min_{z'} \textrm{ cost}(z', z) \textrm{ s.t. } z' \in \mathbb{Z}, f(\phi(z')) = y' \neq y$. Does not consider the feature representation of the input samples.
			\item Because of $\phi$, the problem space attacks cannot use gradient-based methods
		\end{itemize}
		\item Three Unique Challenges of Adversarial Attacks for PE Malware
		\begin{itemize}
			\item Problem-feature space dilemma: $\phi$ can vary and is generally unknown by the attacker, $\phi$ is unlikely to be invertible 
			\item Challenges of maintaining semantics of adversarial PE malware in problem space: , 
			\begin{enumerate}
				\item format preserving: follow format of PE files
				\item executability preserving: keep the file executable
				\item maliciousness preserving: keep the maliciousness intact
			\end{enumerate}
		\item To ensure these properties are maintained, the original and modified malware should be run in a sandbox and their runtime status should be the same
		\end{itemize}
	\end{enumerate}
	\item Adversarial Attacks Against PE Malware Detection: The State of the Art
	\begin{enumerate}
		\item White Box Attacks
		\begin{enumerate}
			\item Feature Space Attacks
			\begin{itemize}
				\item Raw Bytes Detectors: adding/appending bytes to unused section of the PE file, including carefully selected blocks from benign files
				\item API Call List Detectors: various methods to search binary API call space and determine which bits to flip (API calls to add) to create the example
				\item Visualization Detectors: 
				\item Other Detectors: include substituting malicious-looking opcode sequences with equivalent benign-looking ones
			\end{itemize}
			\item Problem Space Attacks
			\begin{itemize}
				\item Almost all are targeted at raw byte based detectors, eg MalConv
				\item Found that MalConv gets most of its information from the PE header file, which leads to injecting raw bytes at the end of the PE header
			\end{itemize}
		\end{enumerate}
		\item Black Box Attacks
		\begin{enumerate}
			\item Feature Space Attacks
			\begin{itemize}
				\item API Call List Detectors: MalGAN, EvnAttack manipulates API imports to mimic goodware
				\item API Call Sequence Detectors: generative RNN, GADGET [110] \& BADGER [109] insert API calls into the code
				\item Other: RL agent for graph-based detectors [148]
			\end{itemize}
			\item Problem Space Attacks
			\begin{itemize}
				\item Reinforcement Learning Attacks: [8,9] completely black box adversarial malware approach and follow up works: [20, 39, 41, 42, 72, 76, 139], [41, 42, 76] ensure functionality
				\item Randomization Attacks: randomly change malware in format-preserving way, then ensure functionality in Cuckoo Sandbox
				\item Evolutionary Algorithm Attacks: AIMED [15], GAMMA [36]
				\item GAN Attacks: GAPGAN [145] dominates MalConv
			\end{itemize}
		\end{enumerate}
		\item Summary of Attacks
		\begin{itemize}
			\item Most white-box attacks use gradient based methods, but to preserve the malware functionality are malware-detector specific
			\item Black box attacks in the feature space develop corresponding manipulations in the problem space, so are malware-detector specific
			\item Black box attacks in the problem space are theoretically the most model agnostic
		\end{itemize}
	\end{enumerate}
	\item Adversarial Defense for PE Malware Detection
	\begin{enumerate}
		\item Adversarial Training: mitigates effect of adversarial attacks, but introduces significant training costs
		\item Other Defense Methods: 
	\end{enumerate}
	\item Discussions
	\begin{enumerate}
		\item Beyond Adversarial Attacks
		\begin{itemize}
			\item Universal Adversarial Perturbation: finding a single perturbation (series of transformations to any arbitrary input object) can be applied over large set of inputs for misclassification
			\item Poisoning Attacks: goal is to make classifier misclassify malware with a specific kind of trigger [113]
			\item Usually the label of the poisoned malware cannot be directly manipulated, only the malware itself
		\end{itemize}
		\item Future Work
		\begin{itemize}
			\item More research on attack methods than attack defense
			\item Attack defenses are usually attack-specific
		\end{itemize}
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Learning to Evade Static PE Machine Learning Malware Models via Reinforcement Learning}

\subsection*{Metadata}

\noindent Authors: Hyrum S. Anderson, Anant Kharkar, Bobby Filar, David Evans, Phil Roth

\noindent Published: 2018

\noindent Read: 08/22

\subsection*{Summary}
\begin{itemize}
	\item Uses RL to create adversarial malware
	\item RL agent randomly modifies malware while preserving its validity
	\item Attacks are black box and modifications are made directly to the malware itself
	\item Source code: \url{https://github.com/endgameinc/gym-malware}
	\item Allows the RL agent to know/use the feature rep of the classifier, but provides arguments ass to why it is not necessary
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item Could be interesting to train an ensemble using dramatically different feature reps, then test an RL, GAN, Graph, and traditional Adversarial malware attacks
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item 
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item DNNs are susceptible to gradient-based attacks; non-differentiable algorithms susceptible to genetic attacks
		\item Proposes a RL based strategy that does not even require a score (black box)
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item Evading ML Models
		\begin{enumerate}
			\item Direct gradient-based attacks: model must be differentiable and the weights must be accessible by attacker
			\item White box against models that report a score (grey box)
			\item Binary black box
		\end{enumerate}
		\item How this work differs:
		\begin{itemize}
			\item Output from classifier is boolean
			\item Feature space and classifier details are unknown
			\item No oracle to guarantee the sample is valid
		\end{itemize}
	\end{itemize}
	\item Methods
	\begin{enumerate}
		\item Reinforcement Learning
		\begin{itemize}
			\item Goal is to derive a policy given a function that estimates the expected utility of a state and an action, $Q$
			\item Deep Q-learning uses a DNN to determine the Q function
			\item Actor Critic model with Experience Replay (ACER) uses DNNs to learn both the policy model $\pi$ and the Q-function
			\item Agent gets an estimate of the environment state $s \in S$, represented by a feature vector of the malware (does not need to correspond to the internal rep of malware used by anti-malware classifier)
			\item Q-function select an action to take from $A$, where allowable actions are any modifications to the PE file that: a) do not break the PE format and b) do not alter the functionality of the malware
			\item Reward is 0 if the adversarial malware is detected, else $R$
		\end{itemize}
		\item Environment
		\begin{itemize}
			\item Malware exists as raw bytes in game environment, but is represented as a state with a $\mathbb{R}^{2350}$ vector (PE header metadata, etc., etc.)
			\item 
		\end{itemize}
		\item Action Space
		\begin{itemize}
			\item A variety of modifications are allowed, such as: manipulating section names, creating new sections, appending bytes, packing/unpacking file etc.
		\end{itemize}
	\end{enumerate}
	\item Experimental Setup
	\begin{itemize}
		\item Uses gradient boosted decision trees
		\item Postulate that agents learning is simpler when 1) feature rep by model under attack has similar learning rep as agent, 2) agent actions are observable by the state representation, 3) agent's actions can impact any part of the feature vector
	\end{itemize}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{A Unified Framework for Adversarial Attack and Defense in Constrained Feature Space}

\subsection*{Metadata}

\noindent Authors: Thibault Simonetto, Salijona Dyrmishi, Salah Ghamizi, Maxime Cordy, Yves Le Traon

\noindent Published: 2021

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Proposes a domain-agnostic unified framework for constrained feature-space attacks
		\item Uses the framework to develop a generic constraint language and two adversarial attack strategies
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item Methods
	\begin{enumerate}
		\item Develops a mathematical model for describing the constraints of adversarial modifications
		\item Uses said model to develop Constrained Projected Gradient Descent (CPGD) and Multi-Objective Generation of Constrained Adversarial Examples
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Adversarial Attacks on Deep-learning Models in Natural Language Processing: A Survey}

\subsection*{Metadata}

\noindent Authors: WEI EMMA ZHANG, QUAN Z. SHENG, AHOUD ALHAZMI, CHENLIANG LI

\noindent Published: 2020

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item 
	\end{itemize}
	\item Overview
	\begin{enumerate}
		\item Deep Learning in NLP involve: FFNNs, CNNs, RNNs/LSTMs/GRUs, Seq2Seqs, Transformers, RL models, GANs/VAEs
	\end{enumerate}
	\item From Image to Text
	\begin{enumerate}
		\item CV methods include: Limited memory Broyden-Fletcher Goldfarb-Shanno algorithm (L-BFGS), Fast Gradient Sign Method (FGSM), JAcobian Saliency Map Adversary (JSMA), C\&W Attack, DeepFool, Substitute Attack, and GAN attacks
		\item Differences between images and text include:
		\begin{itemize}
			\item Discrete vs continuous inputs
			\item Perceivable vs unpercievable perturbations
			\item Semantic vs semanticsless
		\end{itemize}
		\item Vectorizing Textual Inputs
		\begin{itemize}
			\item Word-count encoding: use bag of words to acquire vector rep of text based on word counts
			\item One-hot encoding: each token is assigned a boolean vector where 1 indicates its position in the text
			\item Dense encoding: eg word2vec
		\end{itemize}
		\item Perturbation Measurement
		\begin{itemize}
			\item Norm-based: requires continuous (embedding) representation, but usually results in incomprehensible adversarial texts
			\item Grammar/Syntax Measurements: use grammar or perplexity to ensure adversarial examples are valid
			\item Semantic preserving measurement: use distance functions to ensure semantic meaning of adversarial text is similar
			\item Edit distance measurements: 
			\item Jaccard similarity coefficient: 
		\end{itemize}
	\end{enumerate}
	\item Attack
	\begin{enumerate}
		\item 
	\end{enumerate}
	\item Defense
	\begin{enumerate}
		\item 
	\end{enumerate}
	\item Future Work
	\begin{enumerate}
		\item 
	\end{enumerate}
\end{enumerate}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Evading Anti-Malware Engines With Deep Reinforcement Learning}

\subsection*{Metadata}

\noindent Authors: ZHIYANG FANG, JUNFENG WANG , BOYA LI, SIQI WU, YINGJIE ZHOU , AND HAIYING HUANG

\noindent Published: 2019

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Proposes DQEAF, a deep-Q network to evade anti malware engines
	\item Shown to be more effective than the original RL adversarial approaches
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item How do these RL attacks fare against an ensemble of classifiers?
	\item 
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item ``Automatically evading classifiers'' (2016) genetic programming black box adversarial malware
	\item ``Evading machine learning malware detection'' (2017) the other OG RL adversarial malware attack
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item ``Feature Selection for Malware Detection Based on Reinforcement Learning'' (2019) uses RL to select the optimal features for malware detection
	\item ``Binary Black-box Evasion Attacks Against Deep Learning-based Static Malware Detectors with Adversarial Byte-Level Language Model'' (2020) MalRNN black box attack
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Agent inspects malware then selects a sequence of functionality-preserving actions to modify the samples
		\item Extracts features with a raw binary byte stream
		\item DQEAF has the following:
		\begin{itemize}
			\item only four actions taken (small state space)
			\item low dimensional raw binary stream
			\item high evasion success rate
		\end{itemize}
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item Improvements of this work over other RL approaches are:
		\begin{enumerate}
			\item every action is guaranteed to be effective on all samples
			\item low dimensions of observations reduce instability
			\item priority is taken into consideration during the replay of past transitions
		\end{enumerate}
	\end{itemize}
	\item Methods
	\begin{enumerate}
		\item Primary Concept
		\begin{itemize}
			\item In RL, an agent seeks to learn optimal actions that maximize rewards in an environment
		\end{itemize}
		\item Model Structure
		\begin{itemize}
			\item Uses a Markov Decision Process: $(S, A, \gamma, R(A, S))$, where $S$ is a set of states, $A$ is a set of actions, $\gamma$ is a discount factor, $R(A,S)$ is a reward value after state transition from $s \in S$ to $s' \in S$ 
		\end{itemize}
		\item Environment
		\begin{itemize}
			\item RL agent's environment is the feature rep the agent observes
			\item Used byte histogram counts
		\end{itemize}
		\item Action Space
		\begin{itemize}
			\item larger action spaces make it harder for the RL agent to learn effective policy
			\item ARBE: append random bytes to end of PE file
			\item ARI: append random function to import address table
			\item ARS: append randomly named section to section table of PE file
			\item RS: remove signature from certificate table of DataDiscovery
		\end{itemize}
		\item Reward
		\begin{itemize}
			\item 0 if labeled as malicious
			\item calculated from formula if labeled benign (goal), but reward decreases with respect to the number of turns taken
		\end{itemize}
		\item Agent
		\begin{itemize}
			\item Deep convolutional Q-network
			\item Two CCN networks: Q-value and Q-target
		\end{itemize}
		\item Training
		\begin{itemize}
			\item 
		\end{itemize}
	\end{enumerate}
	\item Performance and Evaluation
	\begin{itemize}
		\item Runs malware in Cuckoo sandbox to ensure the file has not been corrupted
		\item Uses IDA Pro to generate function call graphs, flow charts, and binary files that ensure that the structure and function of the malware is the same
		\item Uses gradient boosted classifier trained on 100k samples using several different kinds of features (different from RL environment)
		\item Supposedly outperforms the original RL-based adversarial attack
	\end{itemize}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Evading Machine Learning Malware Detection}

\subsection*{Metadata}

\noindent Authors: HS Anderson, A Kharkar, B Filar, P Roth

\noindent Published:

\noindent Read:

\subsection*{Summary}
\begin{itemize}
	\item General black box RL adversarial approach with source code: \url{https://github.com/EndgameInc/gym-malware}
	\item Essentially identical to ``Learning to Evade Static PE Machine Learning Malware Models via Reinforcement Learning''
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item 
		\item 
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item Malware attacks largely fall into one of the following categories: direct gradient-based attacks, attacks against models that report a score, binary black box attacks
		\item MalGAN trained surrogate model from binary outputs then used gradients to perturb the malware samples
		\item However, MalGAN requires knowledge of the feature space used to train the surrogate model and the GAN
		\item Furthermore, MalGAN performs perturbations in the feature space and does not create malicious malware
	\end{itemize}
	\item Methods
	\begin{enumerate}
		\item Methodology is essentially identical to ``Learning to Evade Static PE Machine Learning Malware Models via Reinforcement Learning''
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{MERLIN -- Malware Evasion with Reinforcement LearnINg}

\subsection*{Metadata}

\noindent Authors: Tony Quertier, Benjamin Marais, Stephane Morucci, and Bertrand Fournel

\noindent Published: 2022

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Uses RL with DQN and REINFORCE algorithms to create adversarial examples
	\item Performs grey-white-box attacks against MalConv, LGMBM EMBER, and a Grayscale classifier
	\item Successfully performs pure black box attacks against commercial antivirus software, AV
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item First paper I've seen that tests against a commercial AV software
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item ``Bodmas: An open dataset for learning based temporal analysis of PE malware'' (2021)
	\item ``Mal- Fox: Camouflaged Adversarial Malware Example Generation Based on C-GANs Against Black-Box Detectors'' (2020)
	\item ``Functionality-preserving black-box optimization of adversarial windows malware'' (2021) - particularly interesting method based on a constrained minimization problem while preserving executable files functionalities
	\item ``MAB-malware: A reinforcement learning framework for attacking static malware classifiers'' (2020)
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item 
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item Algorithms and RL framework
	\begin{enumerate}
		\item RL Agents
		\begin{itemize}
			\item Deep Q-Network (DQN): uses a DNN to predict the optimal action-value function, Q
			\item Monte Carlo Policy Gradient (REINFORCE): maximizes the expected return of the policy with respect to the parameters 
		\end{itemize}
		\item Environments
		\begin{itemize}
			\item Lets the RL agent know the feature vectors used by the classifiers and the classifier's prediction score
			\item The AV classifier is black box
		\end{itemize}
		\item Actions
		\begin{itemize}
			\item Uses the actions of Anderson et al.
			\item LIEF can make modifications to a PE file, but can sometime break the functionality of the file
			\item During RL, the malware is verified to be functional using Cuckoo sandbox
			\item After a successful evasion, the malware is verified to have the same behavior using other sandbox tools
		\end{itemize}
	\end{enumerate}
	\item Experiments
	\begin{itemize}
		\item BODMAS dataset was hardest to evade, so this dataset was used
		\item MalConv, Greyscale were easy to evade
		\item EMBER and AV were harder to evade, REINFORCE outperformed DQN
		\item In general, REINFORCE took more diverse actions than DQN, which may be responsible for its improved success
	\end{itemize}
\end{enumerate}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section*{Examining Zero-Shot Vulnerability Repair with Large Language Models}

\subsection*{Metadata}

\noindent Authors:  Hammond Pearce, Benjamin Tan, Baleegh Ahmad, Ramesh Karri, Brendan Dolan-Gavitt

\noindent Published: 2023

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Investigates the use of LLMs to fix cyber security issues in code, such as over subscription of arrays in C and improperly sanitized SQL statements in Python
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item Could this strategy be used to ``fix'' portions of suspicious assembly? IE if one particular block of assembly is contributing greatly towards a models assessment that the executable is malware, could that block be ``fixed''
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Investigates the usage of LLM for code to repair identified cyber security bugs in code
		\item Other works attempt to predict the exact tokens that a developer would use to fix the issue
		\item This work attempts to leverage the inherent understanding of LLMs
		\item Asks the following research questions:
		\begin{enumerate}
			\item Can LLMs generate code to fix security vulnerabilities
			\item Does varying the mount of context in comments affect LLMs abilities
			\item What are the challenges in the real world
			\item How reliable are LLMs at generating repairs
		\end{enumerate}
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item RQ1/RQ2: Synthetic Experimentation
	\begin{itemize}
		\item Tries to fix out-of-bounds errors for arrays and improper sanitation errors for SQL statements
	\end{itemize}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagebreak

\section*{Towards Automated Malware Creation: Code Generation and Code Integration}

\subsection*{Metadata}

\noindent Authors: Cani, Andrea and Gaudesi, Marco and Sanchez, Ernesto and Squillero, Giovanni and Tonda, Alberto

\noindent Published: 2014

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Very brief paper.
	\item Use EA algorithms to inject malware into benign program.
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Uses $\mu$GP, an EA toolkit, to 1) make the malware undetectable and optimize the injection of the malware by creating a Trojan Horse
		\item Checks the generated malware for correct behavior
		\item Uses EA algorithm to find the optimal position to inject malicious code inside of a benign executable
		\item Uses a single simple malware program, Timid
		\item Uses an ensemble of freeware AV applications
		\item 
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item Methods
	\begin{enumerate}
		\item 
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Auditing Anti-Malware Tools by Evolving Android Malware and Dynamic Loading Technique}

\subsection*{Metadata}

\noindent Authors: Yinxing Xue, Guozhu Meng, Yang Liu, Tian Huat Tan, Hongxu Chen, Jun Sun, and Jie Zhang

\noindent Published: 2017

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item 6 - GENOME existing benchmarks for android
	\item 7 - DREBIN existing benchmarks for android
	\item 2,3 - DroidChamelion integrated three transformations for AEA android
	\item 11 - previous study focuses on the modelling and code gen- eration for the attack of privacy leakage
	\item 
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item 
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item Methods
	\begin{enumerate}
		\item 
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Evaluating Large Language Models Trained on Code}

\subsection*{Metadata}

\noindent Authors: 

\noindent Published: 2021

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Briefly discusses using codex to create polymorophic malware
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item 
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item Methods
	\begin{enumerate}
		\item 
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{The Potential of Artificial Intelligence as a Method of Software Developer's Productivity Improvement}

\subsection*{Metadata}

\noindent Authors: 

\noindent Published: 2022

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Briefly discusses how the non determinism of codex could be an issue for malware defense
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item 
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item Methods
	\begin{enumerate}
		\item 
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Pop Quiz! Can a Large Language Model Help With Reverse Engineering?}

\subsection*{Metadata}

\noindent Authors: 

\noindent Published: 2022

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Uses LLMs on malware source code, not disassembled binaries
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item 
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item Methods
	\begin{enumerate}
		\item 
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Single-Shot Black-Box Adversarial Attacks Against Malware Detectors: A Causal Language Model Approach}

\subsection*{Metadata}

\noindent Authors: James Hu, Mohammadreza Ebrahimi, Hsinchun Chen

\noindent Published: 2021

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Trains a GPT CLM on malware bytecode to perform single-shot AMG method, MalGPT
	\item MalGPT appends file-specific bytes to an executable
	\item Outperforms other append-style attacks at fooling MalConv
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item Seems to ``test functionality'' using VirusTotal...unsure what that means
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item ``Exploring adversarial examples in malware detection'' (2019) single shot learning AMG
	\item ``Binary black-box evasion attacks against deep learning-based static malware detectors with adversarial byte-level language model'' (2020) DL LMs in malware analysis
	\item ``Black-box attacks against rnn based malware detec- tion algorithms'' (2018) DL LMs in malware analysis
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Adversarial Malware Generation (AMG) is crucial to the success of ML systems
		\item Single shot evasion - one query to the defensive model
		\item Many append-based attacks require numerous queries to the detector before an example can be generated
		\item Detectors usually have query limits, so this is unrealistic
		\item Need for single shit AMG methods as these are the most realistic kind
		\item Casual Language Models (CLMs), eg GPT, are a solution for dealing with extremely long sequences, as is the case if malware is modeled as a byte sequence
		\item Attempts to evade a detector in a single query
	\end{itemize}
	\item Related Work
	\begin{enumerate}
		\item AMGs
		\begin{itemize}
			\item Most studies use VirusTotal dataset
			\item Very few studies perform single shot AMG
		\end{itemize}
		\item CLMs
		\begin{itemize}
			\item Some works have attempted to model malware as language
			\item CLMs incorporate temporal aspects into language modeling and are more well suited to long sequences than traditional LLMs
		\end{itemize}
		\item GPT
		\begin{itemize}
			\item state of the art casual language model
		\end{itemize}
	\end{enumerate}
	\item Methods
	\begin{enumerate}
		\item Threat Model
		\begin{itemize}
			\item Uses a single shot black box setting
			\item Uses append attacks < 10 KB, ie, finds a good place to append certain bytes
		\end{itemize}
		\item MalGPT Architecture
		\begin{itemize}
			\item malware is fed into trained GPT2 model
			\item model generates file-specific byte sequence
			\item sequence appended to original malware sample
			\item malware variant examined for functionality on VirusTotal
		\end{itemize}
		\item GPT2 Model Training
		\begin{itemize}
			\item Trains the GPT model on a set of benign files
		\end{itemize}
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item MalGPT significantly outperformed other append-based attacks on fooling MalConv
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Deep Learning for Android Malware Defenses: a Systematic Literature Review}

\subsection*{Metadata}

\noindent Authors:

\noindent Published:

\noindent Read:

\subsection*{Summary}
\begin{itemize}
	\item 
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item 
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item Methods
	\begin{enumerate}
		\item 
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Evaluating Large Language Models Trained on Code}

\subsection*{Metadata}

\noindent Authors: 

\noindent Published: 2021

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Codex paper, ie, Github Copilot
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item Codex, and other models trained on next token prediction, will generate code that is as similar as possible to the training distribution. Perhaps one could train such a model on benign assembly instructions then use it to complete malicious assembly instructions.
	\item 
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item ``Unsupervised Translation of Programming Languages'' (2020) TransCoder
	\item ``CodeBLEU: a Method for Automatic Evaluation of Code Synthesis'' (2020)
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Scalable sequence prediction models are successful in a variety of disciplines
		\item Codex focusses on the task of generating Python functions from docstrings and evaluating their correctness on unit tests
		\item Finds that with a single generation, Codex can create correct code ~28\% of the time, with multiple, a much higher number
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item Two popular neural approaches to program learning are program induction and program synthesis
		\begin{itemize}
			\item Program induction - model generates outputs directly from latent program representation
			\item Program Synthesis - model generates a program usually from natural language generation
		\end{itemize}
		\item 
	\end{itemize}
	\item Methods
	\begin{itemize}
		\item Fine-tune GPT models on code to produce codex
		\item GPT3 tokenizer is not very effective for representing cod ebecause the distribution of words is so different
		\item Code lexer based on GPT3 text tokenizer
		\item Compared to GPT-Neo and GPT-J, Codex achieves the same performance at a remarkably small model size
	\end{itemize}
	\item Supervised Fine-Tuning
	\begin{itemize}
		\item An additional set of training problems are gathered
		\item Competitive programming: task descriptions/function signatures used as training seed, hidden unit tests used as evaluation
		\item Other data collected from open source continuous integration projects
		\item If Codex-12B cannot produce a single correct function with 100 tries, the sample is considered too ambiguous and discarded
		\item Codex-S is produced by fine-tuning Codex on this data
	\end{itemize}
	\item Conclusions
	\begin{itemize}
		\item Codex is not training efficient. Requires huge amount of data
		\item Codex models do not make malware easier to write, but could assist in creating polymorphic malware (same function, different implementation)
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Improving Language Understanding by Generative Pre-Training}

\subsection*{Metadata}

\noindent Authors: Alec Radford

\noindent Published: 2019

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Original GPT paper
	\item Uses LM in pretraining and task-specific objective + LM in fine-tuning
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Uses a two phase approach: language modeling on unlabeled corpus, then fine-tuning on labeled task-specific corpus
	\end{itemize}
	\item Framework
	\begin{itemize}
		\item Unsupervised pre-training: uses standard language modeling in pre-training
		\item Uses a multilayer Transformer decoder [34] 
		\item Supervised fine-tuning: appends a simple linear layer to the end of the neural network
		\item Also uses a dual training objective in fine tuning: to continue language modeling
	\end{itemize}
	\item Methods
	\begin{enumerate}
		\item 
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{An Adversarial Machine Learning Method Based on OpCode N-grams Feature in Malware Detection}

\subsection*{Metadata}

\noindent Authors: Xiang Liina, Kefan Qiun, Cheng Qian, Gang Zhao

\noindent Published: 2020

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Uses instruction substitution of assembly (rule-based) as an adversarial evasion attack
	\item Only tests their method on ten samples
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item What about replacing larger chunks? Is there a way to prove the functionality of two assembly sequences is the same?
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item  The paper [21] shows that through
	statistical analysis of OpCodes, it is found that there are
	obvious differences between malicious code and normal
	software in the distribution of OpCodes
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item AMG usually revolves around adding garbage instructions to avoid breaking the malware's functionality
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item Methods
	\begin{enumerate}
		\item Feature Representation
		\begin{itemize}
			\item Extracts opcode features from PE samples
			\item args for opcode vary upon CPU arhcitecture, but can include registers, etc.
			\item malware and goodware contain different statistical distributions of opcodes
		\end{itemize}
		\item Feature Extraction
		\begin{itemize}
			\item IDA to disassemble malware
		\end{itemize}
		\item Experiment
		\begin{itemize}
			\item Uses instruction substitution to blur key features (key features?)
			\item example: push ebx; pop ebx; can replace mov eax, ebx
		\end{itemize}
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{PalmTree: Learning an Assembly Language Model for Instruction Embedding}

\subsection*{Metadata}

\noindent Authors: Xuezixiang Li, Yu Qu, Heng Yin

\noindent Published: 

\noindent Read: 

\subsection*{Summary}
\begin{itemize}
	\item Proposes PalmTree: Pre-trained Assembly Language Model for InsTRuction EmbEdding, a general purpose language model scheme for binary analysis based on BERT
	\item Releases source code
	\item Evaluates PalmTree on instruction outlier detection, basic block search, binary code similarity detection, function type signature inference, value set analysis
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item Function boundary detection could be a useful tool for modifying functions
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item Raw-byte Encoding:
	\begin{itemize}
		\item ``Recognizing functions in binaries with neural networks'' (2015) function boundary identification
		\item ``Malware Detection by Eating a Whole EXE'' (2017)
		\item \textbf{``{DeepVSA}: Facilitating Value-set Analysis with Deep Learning for Postmortem Program Analysis'' (2019)}
	\end{itemize}
	\item Manual Encoding of Disassembled Instructions
	\begin{itemize}
		\item \textbf{``Learning Binary Code with Deep Learning to Detect Software Weakness'' (2017) Instruction2Vec}
		\item \textbf{``Neural network-based graph embedding for cross-platform binary code similarity detection'' (2017) Gemini}
		\item ``Graph Matching Networks for Learning the Similarity of Graph Structured Objects'' (2019)
	\end{itemize}
	\item Learning-based Encoding
	\begin{itemize}
		\item ``Neural nets can learn function type signatures from binaries'' (2017)
		\item ``Safe: Self-attentive function embeddings for binary similarity'' (2019)
		\item \textbf{``Asm2vec: Boosting static representation robustness for binary clone search against code obfuscation and compiler optimization'' (2019)}
		\item ``Neural Machine Translation Inspired Binary Code Similarity Comparison beyond Function Pairs'' (InnerEye)
		\item ``Order Matters: Semantic-Aware Neural Networks for Binary Code Similarity Detection'' (2020)
		\item ``DEEPBINDIFF: Learning Program-Wide Code Representations for Binary Diffing'' (2020)
	\end{itemize}
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item ``BinBert: Binary Code Understanding with a Fine-tunable and Execution-aware Transformer'' (2022) apparently outperforms PalmTree
	\item ``Improving cross-platform binary analysis using representation learning via graph alignment'' (2022)
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item DL has been successful in numerous binary analysis tasks, such as function boundary detection, binary code search, function prototype inference, etc.
		\item Can feed to models, raw binary stream (MalConv), manually designed features, or generate vector representation using unsupervised learning eg word2vec then feed to model
		\item Learning vector representation is more attractive because
		\begin{enumerate}
			\item it avoids manual efforts
			\item can learn deeper features rather than pure syntax
		\end{enumerate}
		\item Issues with existing methods add modeling instruction representation
		\begin{enumerate}
			\item Ignore complex internal formats of instructions, eg they treat entire instructions as a word rather
			\item Use control flow graphs which can be obfuscated by compiler optimizations
		\end{enumerate}
		\item Proposes Palm Tree, based on BERT, but trained with different tasks (three tasks)
		\item Evaluates on intrinsic and extrinsic tasks
	\end{itemize}
	\item Background
	\begin{enumerate}
		\item Existing Approaches
		\begin{itemize}
			\item Raw-byte Encoding
			\begin{itemize}
				\item Apply a simple encoding on raw bytes of each instruction then feeds instructions to DNNs
				\item eg one-hot encoding (MalConv, DeepVSA) or [37] encodes each byte (two hex digits) as its 8-D binary representation.
				\item simple/efficient but does not provide any semantic knowledge about instruction
			\end{itemize}
			\item Manual Encoding of Disassembled Instructions
			\begin{itemize}
				\item disassembles each instruction then encodes features from the disassembly
				\item eg one-hot encoding on opcodes [21], one-hot on opcodes and operands [41]
				\item No deeper semantic knowledge of instructions eg add and sub are both arithmetic
			\end{itemize}
			\item Learning based encoding
			\begin{itemize}
				\item automatically learn rep for each instruction that captures high-level semantic information
				\item eg word2vec [26, 43, 5] (on instruction level code), or Asm2Vec [10], which works at the binary level
			\end{itemize}
		\end{itemize} 
		\item Challenges in Learning-based Encoding
		\begin{itemize}
			\item Complex and diverse instruction formats: other learning encoding either ignore the complexities of instructions entirely, or use a very simplified model
			\item Noisy instruction context: the context (other instructions before and after the relevant instruction) can be noisy and irrelevant due to compiler optimizations
			\item 
		\end{itemize}
	\end{enumerate}
	\item Design of PalmTree
	\begin{enumerate}
		\item Overview
		\begin{itemize}
			\item To capture internal instruction format, treat each instruction as a sentence and decompose it into basic tokens
			\item The uses three training tasks: Masked Language Modeling (MLM) (predicts masked tokens), Context Window Prediction (CWP) (similar to next-sentence prediction), and Def Use Prediction (DUP) (predictions of data dependencies)
			\item Architecture is composed of Instruction Pair Sampling (acquires pairs of instructions from binaries), Tokenization (tokenizes instructions), and Model Training (trains on three unsupervised tasks)
			\item Embeddings are generated by using pooling on the final layers of PalmTree
		\end{itemize}
	\item Input Generation
	\begin{itemize}
		\item Disassemble
		\item Retrieve data dependencies for DUP 
		\item Retrieve Instruction pairs for CWP
	\end{itemize}
	\item Tokenization
	\begin{itemize}
		\item Uses rigorous tokenization rules to properly segment instructions into tokens
		\item Sanitizes strings and large numbers with special tokens
	\end{itemize}
	\item Assembly Language Model
	\begin{enumerate}
		\item PalmTree Model: bidirectionally connected stacked transformer units, then fed into BERT model
		\item Training task 1: Masked Language Model
		\item Training task 2: Context Window Prediction
		\item Training task 3: Def-Use Prediction
		\item Instruction Representation: uses mean pooling on the penultimate layer
		\item Deployment of the model: model can be used to generate embeddings or fine-tuned with a targeted application and targeted model
	\end{enumerate}
	\end{enumerate}
	\item Evaluation
	\begin{itemize}
		\item PalmTree and its variants outperform other binary analysis models in both intrinsic and extrinsic tasks
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Leveraging Pre-trained Checkpoints for Sequence Generation Tasks}

\subsection*{Metadata}

\noindent Authors: Sascha Rothe, Shashi Narayan, Aliaksei Severyn

\noindent Published: 2020

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Tests using various transformer variants of encoder-decoder pairs for sequence generation tasks
	\item Experiments with base transformers, pre-trained BERT, GPT, Roberta, and their randomly initalized counterparts
	\item Tests sentence fusion, sentence splitting, machine translation, and text summarization
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Uses combinations of transformer models to produce sequence to sequence models
		\item eg, uses a BERT (encoder) with GPT (decoder) to get the combined encoder decoder effect
		\item Evaluates models on sentence fusion, sentence splitting, machine translation, and text summarization
	\end{itemize}
	\item Models and Pre-trained Checkpoints and Investigated Variants
	\begin{itemize}
		\item Uses seq2seq models composed of encoder-decoder transformers
		\item Tests many different combinations of encoder-decoder pairs
	\end{itemize}
	\item Results
	\begin{enumerate}
		\item Sentence Fusion: RobertaShare performed best
		\item Split and Rephrase: BERTShare performed best
		\item Machine Translation
		\item Text Summarization
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Can we generate shellcodes via natural language? An empirical study}

\subsection*{Metadata}

\noindent Authors: Pietro Liguori, Erfan Al‚ÄëHossami, Domenico Cotroneo, Roberto Natella, Bojan Cukic, Samira Shaikh

\noindent Published: 2020

\noindent Read: 09/16/2022

\subsection*{Summary}
\begin{itemize}
	\item Generates assembly shellcodes from natural language using MT techniques
	\item Distributes a dataset of labeled assembly code
	\item Introduces a metric for evaluating the quality of shellcode
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item codeBERT was pretrained on different languages...don't see how that could work out well...I guess it was pre-trained with English snippets so that could be helpful
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item ShellSwap (Bao et  al. 2017) is a system that generates new exploits based on existing ones, by modifying the original
	shellcode with arbitrary replacement shellcode
	\item For more detailed information on NMT models, we refer the reader to the work of
	Eisenstein (2018)
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item English-Shell code model base don NMT using intent parser and transfer learning
		\item 
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item Numerous works taking natural language to code and the vice-versa
	\end{itemize}
	\item Experimental Analysis
	\begin{enumerate}
		\item Model Implementation: uses Seq2Seq w Attention and pre-trained CodeBERT
		\item Accuracy of NMT at generating assembly code snippets
		\begin{enumerate}
			\item BLEU score
			\item syntactically correct - correctly structured assembly that compiles
			\item semantically correct - an appropriate translation from english to assembly, evaluated at the atomic instruction-level
			\item CodeBERT outperformed seq2seq
		\end{enumerate}
		\item Accuracy of the NMT at generating whole shellcodes
		\begin{itemize}
			\item Uses rigorous syntactic/semanitic definitions of correctedness
			\item Able to generate correct shellcodes 50\% of the time
		\end{itemize}
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Malware Detection Based On Opcode Frequency}

\subsection*{Metadata}

\noindent Authors: Abhijit Yewale, Maninder Singh

\noindent Published: 2016

\noindent Read: 09/16/2022

\subsection*{Summary}
\begin{itemize}
	\item Uses the frequencies of twenty opcodes to classify malware on an absurdly small dataset
	\item Don't ever cite this garbage
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item Absolutely garbage paper
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item ``Opcodes as predictor for malware'' (2007)
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item 
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item Methods
	\begin{enumerate}
		\item 
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Activation Analysis of a Byte-Based Deep Neural Network for Malware Classification}

\subsection*{Metadata}

\noindent Authors: Scott Coull, Christopher Gardner

\noindent Published: 2019

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Investigates the features CNN classifiers learn as part of malware classification
	\item Uses only ransomware and finds greatest activations are in the header
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item byte stream detectors seem to pick up on several key features that can't necessarily be modified using seq2seq stuff
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item ``Representation Learning for Malware Classification'' (2017) byte stream model
	\item ``Deep Convolutional Malware Classifiers Can Learn from Raw Executables and Labels Only'' (2018) byte stream model
	\item ``TESSERACT: Eliminating Experimental Bias in Malware Classification across Space and Time'' (2019) guidelines for malware research datasets
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item ``\textbf{Explaining AI for Malware Detection: Analysis of Mechanisms of MalConv''} (2020)
	\item ``BMOP: Bidirectional Universal Adversarial Learning for Binary OpCode Features'' (2020)
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item This paper investigates the features learned automatically by byte-based DL malware classifiers
		\item Examines at three levels:
		\begin{enumerate}
			\item The embedding layer to uncover learned similarities among byte values
			\item The first convolutional layer to identify low-level features over short byte sequences
			\item End-to-End analysis for complex features learned over several layers
		\end{enumerate}
		Summary of findings:
		\begin{itemize}
			\item Depth is important
			\item code-level features only appear important at lowest levels
			\item end-to-end features are typically similar to those extracted manually by experts
			\item import-related features are present at all levels (eg API imports)
		\end{itemize}
	\end{itemize}
	\item Background
	\begin{enumerate}
		\item Model Architecture: In general, previous works use CNN w embedding layer and various convolutional/pooling layers
		\item Data: Uses large datasets with reasonable class balances
		\item Methodology: Trains three CNNs: baseline, dropout, and small data
	\end{enumerate}
	\item Embedding Layer
	\begin{itemize}
		\item Compare the10D embedding space of each CNN
		\item If bytes can be used interchangeably by classifier, they will be closely clustered
		\item Applies clustering algorithm to the embedding matrix
		\item Finds the small model has least outliers, while baseline+dropout has most outliers
		\item Predilection towards features associated with ASCII strings
	\end{itemize}
	\item Low-Level Features
	\begin{enumerate}
		\item Location of most activations in small model is in the header; becomes more distributed moving the larger models
		\item Filter have two primary types of features: common instruction sequences and ASCII strings (eg import names)
	\end{enumerate}
	\item End-to-End Features
	\begin{itemize}
		\item Uses SHAP explainability after the embedding layer
		\item identifies features typically associated with manual engineering, ie, checksum set to 0, missing standard directories, ImageBase and SectionAlignment, .text/.rdata Section Name, .data Section Information etc.
	\end{itemize}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Explaining AI for Malware Detection: Analysis of Mechanisms of MalConv}

\subsection*{Metadata}

\noindent Authors: Shamik Bose; Timothy Barao; Xiuwen Liu

\noindent Published: 2020

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Finds that MalConv assigns more weight and importance to specific regions of the executable
	\item Finding contradict previous work which found disproportional spikes in the importance of the header of a PE file
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item MalConv using learned PalmTree embeddings, as opposed to its naive embedding
	\item The code itself may actually be fairly important
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item ``Activation analysis of a byte-based deep neural network for malware classification'' (2019) analyzes byte activations of a FireEye NN
	\item \textbf{``Explaining vulnerabilities of deep learning to adversarial malware binaries''} (2019) analyzes feature importance of MalConv to create adversarial examples
	\item ``Adversarial malware binaries: Evading deep learning for malware detection in executables'' (2018) AA against MalConv
	\item ``‚ÄúDeceiving end-to-end deep learning malware detectors using
	adversarial examples'' (2018) AA against MalConv
	\item ``Axiomatic attribution for deep networks'' (2017) feature attribution method
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Training DNNs can require extreme amounts of energy
		\item Analyzes MalConv:
		\begin{itemize}
			\item gradient analysis to see how system assigns weights to different portions of executable
			\item filter weight/activation analysis for different files
		\end{itemize}
		\item Generalization in NNs can be achieved with linear interpolation
	\end{itemize}
	\item Related Work
	\begin{enumerate}
		\item Byte Activation Analysis [20]
		\begin{itemize}
			\item Looks at response of a network to an input and maps activations to various bytes
			\item Used three FireEye CNN detectors: baseline, large, and large-dropout
			\item Byte relationships: hierarchical clustering used to determine which bytes could be easily replaced. Number of outliers grew with model size and dropout
			\item Low-level features: majority of activations happen on a single filter; import name and common instruction features are instrumental to classification
			\item High-level features: a number of feature used by experts are extracted at this level
		\end{itemize}
		\item Adversarial Vulnerability [21]
		\begin{itemize}
			\item Uses feature attribution, where most significant features identified y calculating their gradients
			\item Found that bytes from DOS header are used for classification (even though modern OS doesn't use DOS header except for MZ)
			\item Highest gradient values for the COFF and other headers, .text and .rsrc get minimal weight
		\end{itemize}
	\end{enumerate}
	\item The Network Model
	\begin{enumerate}
		\item MalConv cannot fit into memory on standard GPU, so authors use open source emberMalConv, which is a slightly less massive version of MalConv
	\end{enumerate}
	\item Analysis
	\begin{enumerate}
		\item Gradient Analysis
		\begin{itemize}
			\item In contrast to [21], does not find a massive gradient spike around the header
			\item Large peak at filter \# 45, but do not investigate it
		\end{itemize}
		\item Interpolation between samples
		\begin{itemize}
			\item No fing idea what they are talking about
		\end{itemize}
		\item Filter Correlation
		\begin{itemize}
			\item Filters seem to learn mostly similar features
			\item Filters seem to learn a distinct feature, only one of which is strongly activated
		\end{itemize}
		\item Additional Experiments
		\begin{itemize}
			\item Some filters may be specialized for detecting goodware features and some malware features
		\end{itemize}
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Explaining Vulnerabilities of Deep Learning to Adversarial Malware Binaries}

\subsection*{Metadata}

\noindent Authors: Luca Demetrio, Battista Biggio, Giovanni Lagorio, Fabio Roli, Alessandro Armando

\noindent Published: 2019

\noindent Read: 09/2022

\subsection*{Summary}
\begin{itemize}
	\item Finds that malconv does not learn anything meaningful from .data or .text sections and gains almost all useful information from the header
	\item Proposes an attack that modifies certain parts of header, which is more efficient than others that use extensive padding
	\item Finds that the optional header and .text sections are the most influential to MalConv, but the optional header more so (their analysis is not totally clear)
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Uses feature attribution to explain MalConv
	\end{itemize}
	\item Explaining Machine Learning
	\begin{itemize}
		\item Uses explainability technique called integrated gradients [12]
		\item Contributions of features are measured with respect to a null baseline
		\item Axiom I: Sensitivity - satisfied if, for every input that differ in one feature from the baseline but classified differently, then the attribution of the differing feature should be nonzero.
		\item Axiom II: Implementation Invariance - an attribution
		method satisfies implementation invariance if it produces the same attributions
		for two functionally equivalent networks
		\item Integrated Gradients: for input model $f$, a point $\boldsymbol{x}$ and a baseline $\boldsymbol{x'}$, the attribution for the ith feature is
		$$IG_i(\boldsymbol{x}) = (x_i - x_i') \int_0^1 \frac{\partial f(\boldsymbol{x'} + \alpha(\boldsymbol{x} - \boldsymbol{x'}))}{\partial x_i} d\alpha$$
	\end{itemize}
	\item What Does MalConv Learn
	\begin{enumerate}
		\item Uses an ``empty'' file as baseline, ie, a file filled with special null byte
		\item Finds that the optional header and .text sections are the most influential to MalConv
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Classifying Sequences of Extreme Length with Constant Memory Applied to Malware Detection}

\subsection*{Metadata}

\noindent Authors: Edward Raff, William Fleshman, Richard Zak, Hyrum S. Anderson, Bobby Filar, Mark McLean

\noindent Published: 2021

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Introduced MalConv GCG and MalConv2
	\item Uses temporal max pooling to make MalConv's memory usage invariant to sequence length. Sequences of 100M steps are now possible to be processed
	\item This allows for a more complex global channel gating architecture (GCG) to be used for a new model
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item This is a clear improvement over MalConv, both in terms of efficiency and performance
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item Adversarial attacks against MalConv:
	\begin{itemize}
		\item ``Explaining Vulnerabilities of Deep Learning to Adversarial Malware Binaries'' (2019)
		\item ``Adversarial Malware Binaries: Evading Deep Learning for Malware Detection in Executables'' (2018)
		\item ``Adversarial Examples on Discrete Sequences for Beating Whole-Binary Malware Detection'' (2018)
		\item ``Static Malware Detection \& Subterfuge: Quantifying the Robustness of Machine Learning and Current AntiVirus'' (2018)
	\end{itemize}
	\item ``Non-Negative Networks Against Adversarial Attacks'' (2019) demonstrates attacks can be evaded at cost of reducing MalConv accuracy
	\item (Demetrio et al. 2019; Kolosnjaji et al. 2018; Kreuk et al.
	2018; Fleshman et al. 2018), but these attacks can be thwarted
	at a cost to accuracy (Fleshman et al. 2019)
	\item ``Reformer: The Efficient Transformer'' (2020) Transformer capable of processing 64000 time steps
	\item ``Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks'' (2019) RNN capable of processing 1M time steps
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item ``SeqNet: An Efficient Neural Network for Automatic Malware Detection'' (2022) lightweight raw binary classifier
	\item ``Self-Attentive Models for Real-Time Malware Classification'' (2022) Transformer models for malware detection
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Presents a new pooling approach for MalConv that makes it 116x more memory efficient, 26x faster, and removes input restrictions
		\item Makes memory use invariant to the length of the input
		\item Uses a global channel technique as a new architecture that allows MalConv to use across entire input space
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item MalConv was slightly worse than EMBER, but took significantly less time to train
		\item The maximum file size of 2MB is a huge weakness of MalConv because attackers can just deliver the payload after 2MB of garbage
		\item A few other works look into long sequence classification
		\item A Transformer approach can learn more robust features, but cannot process sequences longer than 64,000 steps
		\item A RNN approach can process sequences up to 1,000,000 steps, but takes thousands of times longer to train than MalConv
	\end{itemize}
	\item Fixed Memory Convolution Over Time
	\begin{itemize}
		\item MalConv Architecture
		\begin{itemize}
			\item embedding layer of $R^8$ used over 257 token alphabet (256 bytes with EndOfFile token)
			\item Fed into two sets of 128 convolutional filters, width=512 and stride=512
			\item then used with gating approach (Dauphin et al. 2017)
			\item gated result converted to fixed length feature vector with temporal max pooling
			\item feature vector fed to fully connected layer for prediction
		\end{itemize}
		\item Architecture had substantial memory requirements for batch training
		\item New model uses temporal max pooling to make the memory usage invariant to the sequence length, $T$
	\end{itemize}
	\item Global Channel Gating
	\begin{itemize}
		\item More diverse architectures can now be investigated since the memory issue has been resolved
		\item Original MalConv had pooling after single conv layer, which means the model could not consider long-term feature interactions
		\item Develops global channel gating (GCG), inspired by attention
	\end{itemize}
	\item Results
	\begin{itemize}
		\item MalConv2 was 20x faster than MalConv; MalConvGCG was 6x faster than MalConv
		\item MalconvGCG was the most accurate model; Malconv and MalConv2 were about the same
	\end{itemize}
	\item What Did Not Work
	\begin{itemize}
		\item Going deeper: using deep CNNs with many layers
		\item Traditional Attention: attention mechanisms are $O(n^2)$ with seuqence length
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Unsupervised Machine Translation Using Monolingual Corpora Only}

\subsection*{Metadata}

\noindent Authors: Guillaume Lample, Alexis Conneau, Ludovic Denoyer, Marc'Aurelio Ranzato

\noindent Published: 2018

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Performs translation using monolingual corpora
	\item encoder-decoder trained to reconstruct original sentence from noisy sentence
	\item The noisy sentence is obtained by either A) dropping/swapping words in it or B) a corrupted translation from the model at the previous iteration
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item This encoder-decoder approach could be used with the super long-range Transformer that can handle sequences of T=64000
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item ``Improving neural machine translation models with monolingual data'' (2015) back-translation, where auxiliary translation system used to supplement labeled data
	\item ``On using monolingual corpora in neural machine translation'' (Gulcehre et al., 2015) (2015) translation that augments the decoder with a language model
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Investigates if its possible to translate without any parallel labeled data
		\item Takes two monolingual corpuses and maps them to the same latent space
		\item Model effectively learns to translate with no labeled data by learning to reconstruct in both languages
		\item Several attempts to leverage monolingual corpora in Mt have been made, including back-translation, augmenting decoder with a language model
		\item Model is unable to compete with supervised models, but still achieves remarkable performance
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item Unsupervised NMT
	\begin{enumerate}
		\item NMT Model
		\begin{itemize}
			\item Uses encoder-decoder architecture with biLSTM-LSTM
		\end{itemize}
		\item Overview of the Method
		\begin{itemize}
			\item Encoder and decoder are trained to reconstruct a sentence, given a noisy version of the sentence
			\item The noisy sentence is obtained by either A) dropping/swapping words  (de-noising auto encoder) or B) a translation from the model at the previous iteration
		\end{itemize}
		\item Denoising Auto Encoding
		\begin{itemize}
			\item The autoencoder with attention would trivially copy word by word 
			\item Adding noisy input lets the model learn meaningful structures in the data (DAE)
		\end{itemize}
		\item Cross Domain Training
		\begin{itemize}
			\item Second training objective is to learn to map sentences from source to target domain
			\item Given a sentence $x \in D_1$, apply current translation model to generate $y = M(x) \in D_2$, then corrupt the translation $C(y) \in D_2$
			\item Objective is to learn the encoder/decoder such that they can reconstruct $x$ from $C(y)$
		\end{itemize}
		\item Adversarial Training
		\begin{itemize}
			\item Decoder of MT only works well when its input is produced by the encoder it was trained with
			\item Trains an adversarial discriminator simultaneously to ultimately allow the decoder to decode into a target language regardless of the language the encoder was trained with
		\end{itemize}
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Unsupervised Neural Machine Translation}

\subsection*{Metadata}

\noindent Authors: Mikel Artetxe, Gorka Labaka, Eneko Agirre, Kyunghyun Cho

\noindent Published: 2018

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Uses denoising auto encoding and on-the-fly back translation for unsupervised machine translation
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item ``Improving neural machine translation models with monolingual data'' (2016) synthetic parallel corpus by backtranslating a monolingual corpus in the target language
	\item `` Copied monolingual data improves low-resource neural machine translation'' (2017) copy target language text is complementary with backtranslation
	\item \textbf{``Unsupervised pretraining for sequence to sequence learning''} (2017)
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item NMT has begun to dominate over SMT (statistical MT)
		\item Provides a method to train NMT systems in a completely unsupervised manner
		\item Builds upon unsupervised cross lingual embeddings
		\item System can be trained with monolingual corpora to reconstruct its input
		\item Noise is introduced via token swaps for denoising
		\item Introduces backtranslation as a secondary training objective
		\item System can be supplemented with labeled data for improved performance
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item embedding mapping methods train embeddings in different languages using monolingual corpora then map them to a shared space
		\item some unsupervised methods to do this involve adversarial training
	\end{itemize}
	\item Proposed Method
	\begin{enumerate}
		\item System Architecture
		\begin{itemize}
			\item uses encoder-decoder RNNs with attention
			\item uses a dual structure (bidirectional translation)
			\item uses a shared encoder that produces a language independent representation of input text
			\item fixes the embeddings of the encoder with unsupervised pretrained cross lingual embeddings
		\end{itemize}
		\item Unsupervised Pretraining
		\begin{itemize}
			\item Trains in unsupervised setting with denoising and on-the-fly back translation
			\item Denoising
			\begin{itemize}
				\item system is trained to reconstruct its own input
				\item this is trivial copying and no useful knowledge is learned
				\item instead random noise is introduced to the input sentences in the form of token swapping
			\end{itemize}
			\item On the Fly Back Translation
			\begin{itemize}
				\item adapts backtranslation
				\item denoising only involves one language
				\item obtains a pseudo parallel sentence pair for an input
				\item trains system to reconstruct original sentence from synthetic translation
			\end{itemize}
		\end{itemize}
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Unsupervised Translation of Programming Languages}

\subsection*{Metadata}

\noindent Authors: Marie-Anne Lachaux, Baptiste Roziere, Lowik Chanussot, Guillaume Lample

\noindent Published: 2020

\noindent Read: 09/16/22

\subsection*{Summary}
\begin{itemize}
	\item Uses an unsupervised model (along with a weakly supervised training step) for code translation
	\item Releases a test set of 852 parallel functions with tests
	\item Uses seq2seq transformers intitialized with pre-trained weights, de-noising autoencoder, and backtranslation
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item Code generation methods that use constraints to the decoder
	\begin{itemize}
		\item ``Neural attribute machines for program generation' (2017)
		\item ``A syntactic neural model for general-purpose code generation'' (2017)
	\end{itemize}
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Code translation tools called transcompiler, transpiler, or source-to-source compiler
		\item This paper focuses on the use case of translating a dead language (little labeled data) to a relevant one
		\item Traditional transcompilation usually involves handcrafted rules and leverages ASTs
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item Most code-to-code translation efforts use supervised methods, which require data and BLEU score as their measurement metric, which is not reliable in this application
		\item Some unsupervised neural models for machine translation have been developed
	\end{itemize}
	\item Model
	\begin{enumerate}
		\item Uses encoder-decoder seq2seq model using transformers
		\item Cross Programming LM Pre-training
		\begin{itemize}
			\item Pre-training ensures sequences with similar meaning are mapped to the same latent expressions
			\item Trains cross lingual language model with MLM objective (XLM)
		\end{itemize}
		\item Denoising auto-encoder
		\begin{itemize}
			\item Initializes the encoder/decoder with the XLM model from pretraining
			\item However decoder cant yet actually perform any translation
			\item Uses de-noising auto encoder (DAE), ie, model is given corrupted sequence of token and tries to predict uncorrupted sequence
			\item DAE also trains language modeling and makes the system robust to noise
		\end{itemize}
		\item Back-translation
		\begin{itemize}
			\item Model still needs to be trained to translate
			\item Use back translation
			\begin{enumerate}
				\item A source-to-target model is paired with a target-to-source model trained in parallel
				\item target-to-source model translates target sequences into noisy source sequences
				\item source-to-target then trained to reconstruct the target sequences from the noisy source
				\item Models trained in parallel until convergence
			\end{enumerate}
		\end{itemize}
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{DOBF: A Deobfuscation Pre-Training Objective for Programming Languages}

\subsection*{Metadata}

\noindent Authors: Marie-Anne Lachaux, Baptiste Roziere, Marc Szafraniec, Guillaume Lample

\noindent Published: 2021

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Introduces a new pretraining objective (DOBF) for source code models
	\item DEOBF replaces class, function, and variable names (all instances of the toen!) and trains the model to recover the names
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item GraphCodeBERT Guo et al. [2020] adds a structure-based pretraining prediction task
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Argue that the MLM pretraining objective is suboptimal for source code 
		\item obfuscation is the process of swapping identifiers etc within code to make it harder to understand what the code does
		\item Presents DOBF: a pretraining objective based on deobfuscation
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item To improve MLM, researchers have proposed oversampling rare tokens, and performing the mask over short sequences
		\item several alternative objectives, like replacing instead of masking tokens, has been shown to improve the language model
		\item 
	\end{itemize}
	\item Methods
	\begin{enumerate}
		\item 
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Leveraging Automated Unit Tests For Unsupervised Code Translation}

\subsection*{Metadata}

\noindent Authors: Baptiste Roziere, Jie M. Zhang, Francois Charton, Mark Harman, Gabriel Synnaeve, Guillaume Lample

\noindent Published: 2022

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Introduced a novel method to grow a parallel corpus for automated code translation, from completely monolingual data
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item Can use parallel functions extracted from GeeksForGeeks along with their units tests. Can compile these functions to obtain correct assembly for verification
	\item Generally speaking, it seems like most unsupervised training methods use DAE + backtranslation to perform tanscompilation 
	\item Instead of using unit tests, could use malware detection as the correct/incorrect input
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item Code Completion
	\begin{itemize}
		\item ``Code completion with neural attention and pointer networks'' (2018)
		\item ``A self-attentional neural architecture for code completion with multi-task learning'' (2020)
		\item ``Code prediction by feeding trees to transformers'' (2021)
		\item ``Fast and memory-efficient neural code completion'' (2021)
	\end{itemize}
	\item ``Measuring coding challenge competence with apps'' (2021) evaluated the competence of several language models for solving coding challenges
	\item Roziere et al. (2020) proposed TransCoder
	\item Later, Roziere et al. (2021)  (DOBF)
	\item \textbf{``Unsupervised translation of programming languages''} (2020) TransCoder
	\item \textbf{``DOBF: A deobfuscation pre-training objective for programming languages''} (2021) improved transcoder
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item A majority of unsupervised MT approaches rely on back translation, which uses noisy inputs
		\item Noisy inputs can make code non-functional as opposed to natural language
		\item Proposes a method that leverages automatic units testing to filter out bad translations, thereby creating a fully tested parallel corpus
		\item Uses EvoSuit, a test generation tool for Java, to generate unit tests, which can be very easily translated between languages
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item Unit Test Generation
		\begin{itemize}
			\item Unit test generation has been of interest for decades
			\item Recently, NN have been used to successfully generate unit tests (Tufano et al., 2020)
			\item This work uses EvoSuite because its open source, widely used, and currently being developed
			\item Uses mutation testing to ensure the unit tests work (deliberately breaks the code to ensure test triggers)
		\end{itemize}
		Machine Learning For Programming Languages
		\begin{itemize}
			\item A variety of pretrained models have been used for code tooling
		\end{itemize}
		\item Translation of Programming Languages
		\begin{itemize}
			\item TransCoder is pretrained with Masked Language Modeling and trained with Denoising Auto Encoder and Back Translation
			\item Using a deobfuscation objective (DOBF) with MLM improves the model
		\end{itemize}
	\end{itemize}
	\item Method
	\begin{enumerate}
		\item Parallel Data Creation
		\begin{itemize}
			\item EvoSuite uses evolutionary algorithms to create tests that maximize some score
			\item only keeps unit test suites with a mutation score larger than 90\% for building parallel dataset
			\item
		\end{itemize}
		\item Training Method
		\begin{itemize}
			\item Uses a pretrained translation model
			\item proposes method for online and offline training
		\end{itemize}
		\item Evaluation
		\begin{itemize}
			\item Uses parallel functions extracted from GeeksForGeeks along with associated unit tests
		\end{itemize}
	\end{enumerate}
	\item Experiments
	\begin{itemize}
		\item uses encoder decoder with transformers (exact same as TransCoder)
		\item uses Google Big Query datasets
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Summarize and Generate to Back-translate: Unsupervised Translation of Programming Languages}

\subsection*{Metadata}

\noindent Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang

\noindent Published: 2022

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item Proposes to perform backtranslation by summarizing and generating code using pretrain code language model PLBART (programming language bidirectional autoregressive transformer)
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item Interesting alternative approach to code translation, but not sure how applicable it would be at the assembly level
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item ``BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension'' (2019) Bidirectional AutoRegressive Transformer
	\item Pretrained Sequence Models for Code
	\begin{itemize}
		\item \textbf{``Unified pre-training for program understanding and generation''} (2021) PLBART, a pretrained code understanding/generation model
		\item \textbf{``CodeT5: Identifier-aware unified pretrained encoder-decoder models for code understanding and generation''} (2021) a pretrained encoder-decoder model which is better suited for seq2seq than encoder/decoder only models
	\end{itemize}
	\item Code Summarization and Generation
	\begin{itemize}
		\item ``Improving automatic source code summarization via deep reinforcement learning'' (2018)
		\item ``. Summarizing source code with transferred api knowledge'' (2018)
		\item ``Recommendations for datasets for source code summarization'' (2019)
		\item ``Codesearchnet challenge: Evaluating the state of semantic code search'' (2019)
	\end{itemize}
	\item ``Multilingual translation from denoising pre-training'' (2021) multilingual fine tuning of BART for NMT
	\item ``The FLORES evaluation datasets for low-resource machine translation: Nepali‚ÄìEnglish and Sinhala‚ÄìEnglish'' (2019) parallel data challenge for NMT
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Investigates suitability of a Pretrained Seq2Seq Model (PSM) for unsupervised PL translation via backtranslation (BT)
		\item Assumes no parallel data is available
		\item Trains a summarize and generate (S\&G) model to generate pseudo parallel code sequences
		\item Works by summarizing source code into natural language then generating target code from the other language
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item Approach
	\begin{enumerate}
		\item
		\begin{itemize}
			\item some sequence to sequence models are pretrained using DAE on several different PLs
			\item these models cannot be used for back translation because their input and output languages are the same, eg, PLBART
		\end{itemize}
		\item Code Summarization and Generation
		\item Backtranslation
		\begin{itemize}
			\item trains source-to-target model and target-to-source model in parallel
			\item target-to-source model produces noisy source examples, from which the source-to-target model must recreate the target from
			\item usually, a small parallel dataset is used to kickstart the training of the forward and backward models
			\item this work initializes the forward/backward models with PLBART
		\end{itemize}
		\item Summarize-Generate to Backtranslate
		\begin{itemize}
			\item since PLBART cannot generate code in a different language than its input, proposes to jointly fine tune the forward/backward PLBART models on summarization and generation respectively
		\end{itemize}
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Phrase-Based \& Neural Unsupervised Machine Translation}

\subsection*{Metadata}

\noindent Authors: Guillaume Lample, Myle Ott, Alexis Conneau, Ludovic Denoyer, Marc'Aurelio Ranzato

\noindent Published: 2018

\noindent Read: 09/22

\subsection*{Summary}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item Two recent (foundational) unsupervised NMT works
	\begin{itemize}
		\item (Lample et al., 2018
		\item Artetxe et al., 2018)
	\end{itemize}
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item existing methods for unsupervised NMT both do the following: 
		\begin{enumerate}
			\item initialize MT system with an inferred bilingual dictionary
			\item train the sequence to sequence model using DAE to create strong LMs
			\item turn unsupervised problem into supervised using backtranslation
			\item constrain the latent representations produced by the encoder to be shared across languages
		\end{enumerate}
		\item creates an NMT model that combines the principals from two previous state of the art works
		\item SMT may outperform NMT when data is scarce
		\item creates a phrase-based SMT model
	\end{itemize}
	\item Principles of Unsupervised MT
	\begin{itemize}
		\item Initialization - essentially the concept of giving the model some apriori knowledge, such as dictionary mappings between languages
		\item Language Modeling - train LMs for both source and target languages
		\item Iterative Back Translation - couple source-to-target translation system with target-to-source system to turn unsupervised approach into noisy supervised
	\end{itemize}
	\item Unsupervised MT Systems
	\begin{enumerate}
		\item Unsupervised NMT
		\begin{itemize}
			\item Initialization
			\item Language Modeling
			\item Back Translation
			\item Sharing Latent Representations
		\end{itemize}
		\item Unsupervised PBSMT
		\begin{itemize}
			\item Initialization
			\item Language Modeling
			\item Back Translation
		\end{itemize}
	\end{enumerate}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Visual interpretability for deep learning: a survey \cite{zhang2018visual}}

\subsection*{Metadata}
\begin{itemize}
	\item Venue Rank:
	\item Venue:
	\item Keywords: Artificial intelligence; Deep learning; Interpretable model
\end{itemize}

\subsection*{Summary}
\begin{itemize}
	\item A survey on explaining CNNs
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item Discusses CNNs that are inherently explainable. Could train one of these as a surrogate model as part of an AA. Then use the surrogate to figure out precisely how to modify the malware.
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item Extract image regions that directly contribute for an assigned label
	\begin{itemize}
		\item propagate gradients of feature maps w.r.t. the final loss back to the image plane to estimate the image regions
		\begin{itemize}
			\item ``Interpretable explanations of black boxes by meaningful perturbation'' (2017)
			\item ``Grad-CAM: visual explanations from deep networks via gradient-based localization'' (2017)
		\end{itemize}
		\item ```Why should I trust you?' explaining the predictions of any classifier'' (2016) the LIME model extracts image regions that are highly sensitive to the network output
		\item Visualize areas in the input image that contribute the most to the decision-making
		\begin{itemize}
			\item ``Visualizing deep neural network decisions: prediction difference analysis'' (2017)
			\item ``Learning how to explain neural networks: patternnet and pattern attribution'' (2017)
			\item ``Explaining the unexplained: a class-enhanced attentive response (clear) approach to understanding deep neural networks'' (2017)
		\end{itemize}
	\end{itemize}
	\item ``One pixel attack for fooling deep neural networks'' (2019) estimation of vulnerable points in the feature space of CNN for AA
	\item \textbf{``Interpreting CNNs via decision trees''} (2018) use Decision Tree to explain which filters contribute to the models prediction
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item explores five research directions:
		\begin{enumerate}
			\item visualization of CNN representations in intermediate layers
			\item diagnosis of CNN representations
			\item disentanglement of ‚Äòthe mixture of patterns‚Äô encoded in each filter of CNNs
			\item building explainable models
			\item semantic-level middle-to-end learning via human‚Äìcomputer interaction
		\end{enumerate}
	\end{itemize}
	\item Visualization of CNN Representations
	\begin{itemize}
		\item visualization of the filters in a CNN is the most direct way of explaining them
		\item gradient methods estimate the image appearance that maximizes a given CNN unit's score
		\item the up-convolutional net inverts CNN feature maps to images
	\end{itemize}
	\item Diagnosis of CNN Representations
	\begin{itemize}
		\item going beyond visualization to actually diagnosing CNN representations
		\item five directions
		\begin{enumerate}
			\item analyze CNN features from global view
			\item \textbf{extract image regions that directly contribute for an assigned label}
			\item estimation of vulnerable points in the feature space of CNN
			\item refine network representations based on the analysis of network feature spaces
			\item discover biased representations of a CNN
		\end{enumerate}
	\end{itemize}
	\item Disentangling CNN Representations in Explanatory Graphs and Decision Trees
	\begin{enumerate}
		\item Explanatory Graphs
		\begin{itemize}
			\item disentangle features in Conv layers and use graphical model to represent semantic hierarchy hidden within CNN
		\end{itemize}
		\item Decision Trees
		\begin{itemize}
			\item dt not used for predictions
			\item dt explains which filters are used in a conv layer and how much they contribute to a prediction
		\end{itemize}
		\begin{itemize}
			\item 
		\end{itemize}
	\end{enumerate}
	\item Learning NNs with Interpretable Representations
	\item Evaluation Metrics for Network Interpretability
	\item Network Interpretability for Middle-to-End Learning
	\item Prospective Trends and Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Axiomatic Attribution for Deep Networks}

\subsection*{Metadata}
\begin{itemize}
	\item Venue Rank:
	\item Venue:
	\item Citations: 
	\item Keywords: 
\end{itemize}

\subsection*{Summary}
\begin{itemize}
	\item Identifies two fundamental axioms of explainability methods and uses them to develop Integrated Gradients
	\item Examples can be found at \url{https://github.com/ankurtaly/Integrated-Gradients}
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item An attribution for a neural network $F: \mathbb{R}^n  \rightarrow [0, 1]$ on an input $x = (x_1, \dots, x_n) \in \mathbb{R}^n$ relative to a baseline $x'$ is a vector $A_F(x, x') = (a_1, \dots, a_n)$
	\end{itemize} 
	\item Fundamental Axioms
	\begin{enumerate}
		\item Sensitivity
		\begin{itemize}
			\item A method satisfies sensitivity if for every input and baseline that differ by one feature but have different predictions, then the differing feature should be given nonzero attribution
		\end{itemize}
		\item Implementation Invariance
		\begin{itemize}
			\item A method satisfies implementation invariance if two functionally equivalent networks have the same attribution
		\end{itemize}
	\end{enumerate}
	\item Integrated Gradients
	\begin{itemize}
		\item Consider the straightline path in $\mathbb{R}^n$ from $x$ to $x'$
		\item Integrated Gradients are the path integral of the gradients along this line
		\item For the $i$th dimension for an input $x$ and baseline $x'$ and function $F: \mathbb{R}^n \rightarrow [0, 1]$,
		$$IG_i(x) = (x_i - x_i') \int_{0}^1 d\alpha \;\; \partial_{x_i} F(x' + \alpha(x-x')) $$
		\item Proposition 1: if $F: \mathbb{R}^n \rightarrow \mathbb{R}$ is differentiable almost everywhere (Sigmoids, ReLUs, and pooling operators) then 
		$$\sum{i=1}^n IG_i(x) = F(x) - F(x')$$
	\end{itemize}
	\item Uniqueness of Integrated Gradients
	\begin{itemize}
		\item IG is one method belonging to a class of methods called path methods which all satisfy the two axioms
		\item IG is the canonical method among path methods
	\end{itemize}
	\item Applying IG
	\begin{itemize}
		\item The baseline should have a near zero score and convey a complete absense of signal
		\item Ex black image or all zero input for text
		\item IG can be approximated with summation (Riemman approx)
		$$IG_i(x) \approx \frac{1}{m}(x_i - x_i') \sum_{k=1}^m \partial_{x_i} F(x' + \frac{k}{m} (x - x'))$$
		\item $m$ between 20 and 300 usually works well, but Proposition 1 should be verified
	\end{itemize}
	\item Applications
	\begin{itemize}
		\item For ImageNet, gradients are computed for the output of the highest scoring class with respect to the pixel of the input image
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Polynomial calculation of the Shapley value based on sampling \cite{castro2009polynomial}}

\subsection*{Metadata}
\begin{itemize}
	\item Venue Rank: 
	\item Venue:
	\item Citations: 
	\item Keywords: 
\end{itemize}

\subsection*{Summary}
\begin{itemize}
	\item This is essentially a polynomial algorithm for computing SHAP values
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Shapley Value: useful when there exists a need to allocate the worth that a set of players can achieve if they agree to cooperate
		\item Finding the SHAP value is an NP complete problem
		\item Methods to estimate the SHAP value are needed
	\end{itemize}
	\item Preliminaries
	\begin{itemize}
		\item 
	\end{itemize}
	\item The estimation of the Shapley Value
	\begin{enumerate}
		\item 
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{A unified approach to interpreting model predictions}

\subsection*{Metadata}
\begin{itemize}
	\item Venue Rank:
	\item Venue:
	\item Citations: 
	\item Keywords: 
\end{itemize}

\subsection*{Summary}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item A wide variety of methods to explain models: e [5, 8, 9, 3, 4, 1].
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item Argues that any explanation method is a model itself, and introduces additive feature attribution methods
		\item Proposes SHAP values as a unified measure of feature importance that various methods approximate
		\item SHAP value estimation are better aligned with human intuition
	\end{itemize}
	\item Aditive Feature Attribution Methods
	\begin{itemize}
		\item let $f$ be the original model and $g$ the explanation model
		\item explanation models often use simplified inputs, $x'$ s.t. $x = h_x(x')$, where $h_x$ is a mapping function
		\item local methods try to keep $g(z') \approx f(h_x(z'))$ when $z' \approx x'$
		\item Definition: Additive Feature Attribution Methods have an explanation model that is a linear function of binary variables 
		$$g(z') = \phi_0 + \sum_{i=1}^{M} \phi_i z_i'$$
		\item where $z' \in \{ 0, 1 \}^M$ and $\phi_i$ is the attributed effect to each feature in $z'$
		\item Argues that LIME, DeepLift, Layer-wise Relevance Propagation, and Classic Shapley Value Estimation are all implementations of this unifying theory
	\end{itemize}
	\item Simple Properties Uniquely Determine Additive Feature Attributions
	\begin{itemize}
		\item Local Accuracy: the explanasion model must match the output of f for te simplified x' $f(x) = g(x')$
		\item Missingness: $x_i' = 0 \implies \phi_i = 0$ features missing in the original input must have no impact
		\item Consistency: if a simplified inputs contribution increases or stays the same, then that inputs attribution should not decrease
		\item Then only one possible explansion model can exist:
		$$\phi_i(f, x) = \sum_{z' \subset x'} \frac{|z'|! (M-|z'|-1)!}{M!} [f_x(z') - f_x(z' \ i)]$$
	\end{itemize}
	\item SHAP (Shapley Additive exPlation) Values
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% TEMPLATE %%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{}

\subsection*{Metadata}
\begin{itemize}
	\item Venue Rank:
	\item Venue:
	\item Citations: 
	\item Keywords: 
\end{itemize}

\subsection*{Summary}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Thoughts}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Cited By}
\begin{itemize}
	\item
\end{itemize}

\subsection*{Notes}

\begin{enumerate}
	\item Introduction
	\begin{itemize}
		\item 
	\end{itemize}
	\item Related Work
	\begin{itemize}
		\item 
	\end{itemize}
	\item Methods
	\begin{enumerate}
		\item 
	\end{enumerate}
	\item Conclusions
	\begin{itemize}
		\item 
	\end{itemize}
\end{enumerate}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{./IEEEtran}
\bibliography{master.bib}

\end{document}